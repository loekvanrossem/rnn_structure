{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from numba import njit, prange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from data import addition_dataset\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "from preprocessing import OneHot, Encoding\n",
    "from compilation import Compiler, ScalarTracker, ActivationTracker\n",
    "from data_analysis.automata import to_automaton_history\n",
    "from visualization.animation import SliderAnimation\n",
    "from visualization.activations import ActivationsAnimation\n",
    "from visualization.automata import AutomatonAnimation\n",
    "from visualization.epochs import EpochAnimation\n",
    "\n",
    "import publication\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [str(n) for n in range(10)] + [\"+\", \" \"]\n",
    "onehot = OneHot(symbols)\n",
    "\n",
    "\n",
    "class SequenceEncoder(Encoding):\n",
    "    def __init__(self, single_encoder: Encoding):\n",
    "        self._decoding = lambda x: x\n",
    "        self.single_encoder = single_encoder\n",
    "\n",
    "    # @property\n",
    "    # def symbols(self) -> list:\n",
    "    #     return None\n",
    "\n",
    "    # def _update_decoding(self, encoding):\n",
    "    #     pass\n",
    "\n",
    "    def __call__(self, data):\n",
    "        encoded = [self.single_encoder(char) for char in data]\n",
    "        encoded = encoded[::-1]  # decoded in reverse for better computation\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, enc_data):\n",
    "        enc_data = enc_data.to(\"cpu\").detach()\n",
    "        decoded = [self.single_encoder.decode(vec) for vec in enc_data]\n",
    "        decoded = \"\".join(decoded)\n",
    "        decoded = decoded[::-1]\n",
    "        return decoded\n",
    "\n",
    "\n",
    "encoder = SequenceEncoder(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate data\n",
    "\n",
    "full_length = 100\n",
    "max_train_length = 12\n",
    "test_length = 13\n",
    "\n",
    "test_data = addition_dataset(\n",
    "    device, encoder, n_datapoints=100, seq_len=[test_length], full_length=full_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, device, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm_encoder = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.lstm_decoder = nn.LSTM(\n",
    "            input_size=hidden_size * 2,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm_encoder(x)\n",
    "        x, _ = self.lstm_decoder(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    device,\n",
    "    input_size=len(symbols),\n",
    "    hidden_size=100,\n",
    "    num_layers=1,\n",
    "    output_size=len(symbols),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input, model):\n",
    "    out = model(input)\n",
    "    pred = torch.argmax(out, axis=1).int()\n",
    "    string = \"\".join([symbols[index] for index in pred])\n",
    "\n",
    "    string = string[::-1]\n",
    "    return string\n",
    "\n",
    "\n",
    "def score(dataset, model):\n",
    "    count = 0\n",
    "    n_datapoints = len(dataset)\n",
    "    for n in prange(n_datapoints):\n",
    "        x, y = dataset[n]\n",
    "        target = encoder.decode(y)\n",
    "        prediction = predict(x, model)\n",
    "        if target == prediction:\n",
    "            count += 1\n",
    "    acc = count / len(dataset)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train RMSE 0.0765, test RMSE 0.1061, train score 0.00, test score 0.00\n",
      "Epoch 50: train RMSE 0.0500, test RMSE 0.0728, train score 0.02, test score 0.02\n",
      "Epoch 100: train RMSE 0.0421, test RMSE 0.0635, train score 0.12, test score 0.05\n",
      "Epoch 150: train RMSE 0.0387, test RMSE 0.0599, train score 0.31, test score 0.07\n",
      "Epoch 200: train RMSE 0.0363, test RMSE 0.0575, train score 0.40, test score 0.07\n",
      "Epoch 250: train RMSE 0.0342, test RMSE 0.0570, train score 0.41, test score 0.09\n",
      "Epoch 300: train RMSE 0.0320, test RMSE 0.0522, train score 0.50, test score 0.09\n",
      "Epoch 350: train RMSE 0.0296, test RMSE 0.0524, train score 0.61, test score 0.12\n",
      "Epoch 400: train RMSE 0.0290, test RMSE 0.0500, train score 0.63, test score 0.16\n",
      "Epoch 450: train RMSE 0.0283, test RMSE 0.0491, train score 0.56, test score 0.17\n",
      "Epoch 500: train RMSE 0.0269, test RMSE 0.0478, train score 0.64, test score 0.26\n",
      "Epoch 550: train RMSE 0.0266, test RMSE 0.0485, train score 0.74, test score 0.25\n",
      "Epoch 600: train RMSE 0.0245, test RMSE 0.0466, train score 0.84, test score 0.35\n",
      "Epoch 650: train RMSE 0.0250, test RMSE 0.0460, train score 0.73, test score 0.38\n",
      "Epoch 700: train RMSE 0.0251, test RMSE 0.0457, train score 0.71, test score 0.38\n",
      "Epoch 750: train RMSE 0.0231, test RMSE 0.0449, train score 0.77, test score 0.41\n",
      "Epoch 800: train RMSE 0.0237, test RMSE 0.0461, train score 0.80, test score 0.37\n",
      "Epoch 850: train RMSE 0.0222, test RMSE 0.0442, train score 0.80, test score 0.45\n",
      "Epoch 900: train RMSE 0.0222, test RMSE 0.0441, train score 0.80, test score 0.46\n",
      "Epoch 950: train RMSE 0.0218, test RMSE 0.0440, train score 0.87, test score 0.40\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=32)\n",
    "\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    # Generate data\n",
    "    train_data = addition_dataset(\n",
    "        device,\n",
    "        encoder,\n",
    "        n_datapoints=1000,\n",
    "        seq_len=[x for x in range(3, max_train_length) if x != test_length],\n",
    "        full_length=full_length,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=32)\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    if epoch % 50 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(train_data.tensors[0])\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, train_data.tensors[1]).cpu())\n",
    "        y_pred = model(test_data.tensors[0])\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, test_data.tensors[1]).cpu())\n",
    "        train_score = score(torch.utils.data.Subset(train_data, np.arange(100)), model)\n",
    "        test_score = score(test_data, model)\n",
    "    print(\n",
    "        f\"Epoch {epoch}: train RMSE {train_rmse:.4f}, test RMSE {test_rmse:.4f}, train score {train_score:.2f}, test score {test_score:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 5+5                                                                                                 \n",
      "target: 10                                                                                                  \n",
      "prediction: 10                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "\n",
    "print(f\"input: {encoder.decode(train_data[index][0])}\")\n",
    "print(f\"target: {encoder.decode(train_data[index][1])}\")\n",
    "print(f\"prediction: {predict(train_data[index][0], model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 97018+3037372                                                                                       \n",
      "target: 3134390                                                                                             \n",
      "prediction: 3305550                                                                                             \n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "\n",
    "print(f\"input: {encoder.decode(test_data[index][0])}\")\n",
    "print(f\"target: {encoder.decode(test_data[index][1])}\")\n",
    "print(f\"prediction: {predict(test_data[index][0], model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 10000000+4000000                                                                                    \n",
      "prediction: 14002227                                                                                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29845/4282626021.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(f\"prediction: {predict(torch.tensor(encoded), model)}\")\n"
     ]
    }
   ],
   "source": [
    "example = \"10000000+4000000\"\n",
    "example = example + \" \" * (full_length - len(example))\n",
    "\n",
    "print(f\"input: {example}\")\n",
    "encoded = torch.tensor(encoder(example), device=device, dtype=torch.float32)\n",
    "print(f\"prediction: {predict(torch.tensor(encoded), model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000000000000000000000000000000000000000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_a_len = 50\n",
    "10 ** (int_a_len - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high is out of bounds for int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_a_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_a_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:782\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/_bounded_integers.pyx:1332\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high is out of bounds for int64"
     ]
    }
   ],
   "source": [
    "np.random.randint(10 ** (int_a_len - 1), 10 ** (int_a_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Random.getrandbits() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetrandbits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Random.getrandbits() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.getrandbits(1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 18/28 [00:01<00:01,  9.73it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m3\u001b[39m, N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     val_data \u001b[38;5;241m=\u001b[39m \u001b[43maddition_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_datapoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_length\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     val_score \u001b[38;5;241m=\u001b[39m score(val_data, model)\n\u001b[1;32m     11\u001b[0m     val_scores\u001b[38;5;241m.\u001b[39mappend(val_score)\n",
      "File \u001b[0;32m~/projects/rnn_structure/addition/data.py:55\u001b[0m, in \u001b[0;36maddition_dataset\u001b[0;34m(device, encoding, n_datapoints, seq_len, full_length)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_datapoints):\n\u001b[1;32m     54\u001b[0m     length \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(seq_len)\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28minput\u001b[39m, output \u001b[38;5;241m=\u001b[39m \u001b[43maddition_datapoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28minput\u001b[39m, output \u001b[38;5;241m=\u001b[39m encoding(\u001b[38;5;28minput\u001b[39m), encoding(output)\n\u001b[1;32m     57\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/projects/rnn_structure/addition/data.py:16\u001b[0m, in \u001b[0;36maddition_datapoint\u001b[0;34m(length, full_length)\u001b[0m\n\u001b[1;32m     14\u001b[0m int_b_len \u001b[38;5;241m=\u001b[39m length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m int_a_len\n\u001b[1;32m     15\u001b[0m int_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (int_a_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (int_a_len))\n\u001b[0;32m---> 16\u001b[0m int_b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_b_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_b_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mint_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mint_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mint_a\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mint_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:782\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/_bounded_integers.pyx:1334\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "## Check for large sequence length generalization\n",
    "\n",
    "# Evaluate model generalization for sequences of varying lengths\n",
    "N = 20\n",
    "val_scores = []\n",
    "for n in trange(3, N + 1):\n",
    "    val_data = addition_dataset(\n",
    "        device, encoder, n_datapoints=10, seq_len=[n], full_length=full_length\n",
    "    )\n",
    "    val_score = score(val_data, model)\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "# Visualize validation error for varying sequence lengths\n",
    "publication.set_color_mixed()\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "ax.bar(np.arange(3, N + 1), val_scores, color=\"skyblue\")\n",
    "ax.set_xlabel(\"Sequence lengths\")\n",
    "ax.set_ylabel(\"Validation error\")\n",
    "ax.set_title(\"Model Generalization Across Sequence Lengths\")\n",
    "ax.set_yticks(np.arange(0, 1, 0.1))\n",
    "publication.pub_show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_structure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
