{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f44528a9330>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "\n",
    "from data import seq_data\n",
    "from preprocessing import OneHot\n",
    "from compilation import Compiler, ScalarTracker, ActivationTracker\n",
    "from data_analysis.automata import to_automaton_history, reduce_automaton, to_automaton\n",
    "from visualization.animation import SliderAnimation\n",
    "from visualization.activations import ActivationsAnimation\n",
    "from visualization.automata import AutomatonAnimation, display_automata\n",
    "from visualization.epochs import EpochAnimation\n",
    "\n",
    "from model import Model\n",
    "import publication\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinearity, lr, P, L, n_epochs = \"tanh\", 0.001, 100, 1, 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(gain, seq_len):\n",
    "    ## Generate data\n",
    "\n",
    "    # Define problem and data encoding\n",
    "    symbols = [0, 1]\n",
    "    encoding = OneHot(symbols)\n",
    "    problem = lambda seq: np.sum(seq) % 2  # XOR problem\n",
    "\n",
    "    # Define sequence lengths for training and validation datasets\n",
    "    train_seq_lengths = list(range(1, seq_len + 1))\n",
    "    analysis_seq_lengths = train_seq_lengths\n",
    "    val_seq_length = 50\n",
    "    val_datapoints = 100\n",
    "\n",
    "    # Generate datasets\n",
    "    training_datasets = [\n",
    "        seq_data(device, problem, encoding, seq_len=length)\n",
    "        for length in train_seq_lengths\n",
    "    ]\n",
    "    validation_datasets = [\n",
    "        seq_data(\n",
    "            device,\n",
    "            problem,\n",
    "            encoding,\n",
    "            n_datapoints=val_datapoints,\n",
    "            seq_len=val_seq_length,\n",
    "        )\n",
    "    ]\n",
    "    analysis_data = [\n",
    "        seq_data(device, problem, encoding, seq_len=length)\n",
    "        for length in analysis_seq_lengths\n",
    "    ]\n",
    "    tracked_datasets = validation_datasets + analysis_data + training_datasets\n",
    "\n",
    "    ## Instantiate model\n",
    "    model = Model(\n",
    "        encoding=encoding,\n",
    "        input_size=2,\n",
    "        output_size=2,\n",
    "        hidden_dim=P,\n",
    "        n_layers=L,\n",
    "        device=device,\n",
    "        nonlinearity=nonlinearity,\n",
    "        gain=gain,\n",
    "    )\n",
    "\n",
    "    ## Setup compiler\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=lr, amsgrad=True, weight_decay=0.01\n",
    "    )\n",
    "    compiler = Compiler(model, criterion, optimizer)\n",
    "    compiler.trackers = {\n",
    "        \"loss\": ScalarTracker(lambda: compiler.validation(tracked_datasets)),\n",
    "    }\n",
    "\n",
    "    ## Training run\n",
    "    compiler.training_run(\n",
    "        training_datasets,\n",
    "        n_epochs=n_epochs,\n",
    "        batch_size=128,\n",
    "        progress_bar=False,\n",
    "    )\n",
    "\n",
    "    ## Collect data\n",
    "    loss = compiler.trackers[\"loss\"].get_trace()\n",
    "    val_loss = loss.query(\"Dataset==0\")[0].to_numpy()[-1]\n",
    "    train_loss = loss.query(\"Dataset>0\").groupby(\"Epoch\").mean().to_numpy()[-1]\n",
    "    initial_hidden = model.init_hidden(batch_size=1)[-1]\n",
    "    hidden_function = lambda inputs: model(inputs)[1][-1]\n",
    "    output_function = lambda inputs: model(inputs)[0]\n",
    "    automaton = to_automaton(\n",
    "        hidden_function,\n",
    "        output_function,\n",
    "        initial_hidden,\n",
    "        training_datasets,\n",
    "        encoding,\n",
    "        merge_distance_frac=0.1,\n",
    "    )\n",
    "    n_states = len(automaton.states)\n",
    "\n",
    "    return train_loss, val_loss, n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/ghome/live/vanrosseml/mambaforge/envs/rnn_structure/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Training: 100%|██████████| 10000/10000 [02:20<00:00, 71.15steps/s, train_loss=0.00010, val_loss=0.65862]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 531.06it/s]\n",
      "Training: 100%|██████████| 10000/10000 [02:54<00:00, 57.15steps/s, train_loss=0.00228, val_loss=0.40487]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 334.13it/s]\n",
      "Training:  13%|█▎        | 1298/10000 [00:27<04:25, 32.82steps/s, train_loss=0.00804, val_loss=0.54798]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training: 100%|██████████| 10000/10000 [03:35<00:00, 46.43steps/s, train_loss=0.00430, val_loss=0.38639]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 262.52it/s]\n",
      "Training: 100%|██████████| 10000/10000 [04:26<00:00, 37.59steps/s, train_loss=0.02804, val_loss=0.28681]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 55.97it/s]\n",
      "Training: 100%|██████████| 10000/10000 [05:10<00:00, 32.25steps/s, train_loss=0.00698, val_loss=0.06219]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 119.01it/s]\n",
      "Training:  42%|████▏     | 4196/10000 [02:37<03:26, 28.16steps/s, train_loss=0.00668, val_loss=0.02841]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  75%|███████▌  | 7534/10000 [04:44<01:36, 25.55steps/s, train_loss=0.00629, val_loss=0.02582]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training: 100%|██████████| 10000/10000 [06:19<00:00, 26.34steps/s, train_loss=0.00603, val_loss=0.02331]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 58.16it/s]\n",
      "Training:   4%|▍         | 431/10000 [00:20<07:24, 21.51steps/s, train_loss=0.25017, val_loss=0.25252]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  36%|███▌      | 3560/10000 [02:47<04:54, 21.90steps/s, train_loss=0.00549, val_loss=0.01479]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  66%|██████▌   | 6551/10000 [05:07<02:41, 21.33steps/s, train_loss=0.00507, val_loss=0.01344]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  97%|█████████▋| 9744/10000 [07:37<00:11, 21.58steps/s, train_loss=0.00456, val_loss=0.01114]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  24%|██▍       | 2392/10000 [02:40<08:22, 15.14steps/s, train_loss=0.00323, val_loss=0.00531]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  52%|█████▏    | 5162/10000 [05:48<05:40, 14.20steps/s, train_loss=0.00322, val_loss=0.00535]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  89%|████████▉ | 8890/10000 [10:02<01:13, 15.07steps/s, train_loss=0.00321, val_loss=0.00534]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training: 100%|██████████| 10000/10000 [11:16<00:00, 14.79steps/s, train_loss=0.00318, val_loss=0.00524]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]\n",
      "Training:  13%|█▎        | 1262/10000 [02:16<15:33,  9.36steps/s, train_loss=0.25080, val_loss=0.24850]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training:  35%|███▍      | 3452/10000 [06:12<11:35,  9.41steps/s, train_loss=0.25104, val_loss=0.24841]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training: 100%|██████████| 10000/10000 [18:22<00:00,  9.07steps/s, train_loss=0.00215, val_loss=0.00291]\n",
      "Computing automata: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
      "Training:   8%|▊         | 781/10000 [02:31<29:05,  5.28steps/s, train_loss=0.25021, val_loss=0.24817]"
     ]
    }
   ],
   "source": [
    "N_gain, N_len = 10, 10\n",
    "\n",
    "gains = np.linspace(0.1, 2.0, N_gain)\n",
    "seq_lens = np.linspace(1, 10, N_len, dtype=int)\n",
    "gain_data, seq_len_data, train_loss_data, val_loss_data, n_states_data = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "for gain in gains:\n",
    "    for seq_len in seq_lens:\n",
    "\n",
    "        train_loss, val_loss, n_states = trial(gain, seq_len)\n",
    "        for data, item in zip(\n",
    "            (gain_data, seq_len_data, train_loss_data, val_loss_data, n_states_data),\n",
    "            (gain, seq_len, train_loss, val_loss, n_states),\n",
    "        ):\n",
    "            data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, name in zip(\n",
    "    (gain_data, seq_len_data, train_loss_data, val_loss_data, n_states_data),\n",
    "    (\"gain\", \"seq_len\", \"train_loss\", \"val_loss\", \"n_states\"),\n",
    "):\n",
    "    np.save(name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "train_loss_grid = np.array(train_loss_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "publication.set_color_gradient(2)\n",
    "plt.imshow(train_loss_grid)\n",
    "publication.im_show(colorbar=False, x_labels=np.around(gains, 1), y_labels=seq_lens,save_path=\"train_loss_grid\")\n",
    "\n",
    "val_loss_grid = np.array(val_loss_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "publication.set_color_gradient(2)\n",
    "plt.imshow(train_loss_grid)\n",
    "publication.im_show(colorbar=False, x_labels=np.around(gains, 1), y_labels=seq_lens,save_path=\"val_loss_grid\")\n",
    "\n",
    "n_states_grid = np.array(n_states_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "publication.set_color_gradient(2)\n",
    "plt.imshow(train_loss_grid)\n",
    "publication.im_show(colorbar=False, x_labels=np.around(gains, 1), y_labels=seq_lens,save_path=\"n_states_grid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_structure",
   "language": "python",
   "name": "rnn_structure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e02af9847f8f14625728f2f7147d07d87bda9043f1b0a8cf0822fa7c64756065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
