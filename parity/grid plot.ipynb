{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import trange,tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "\n",
    "from data import seq_data\n",
    "from preprocessing import OneHot\n",
    "from compilation import Compiler, ScalarTracker, ActivationTracker\n",
    "from data_analysis.automata import to_automaton_history, reduce_automaton, to_automaton, has_all_transitions\n",
    "from visualization.animation import SliderAnimation\n",
    "from visualization.activations import ActivationsAnimation\n",
    "from visualization.automata import AutomatonAnimation, display_automata\n",
    "from visualization.epochs import EpochAnimation\n",
    "\n",
    "from model import Model\n",
    "import publication\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinearity, lr, P, L, n_epochs = \"tanh\", 0.001, 100, 1, 15000\n",
    "\n",
    "N_gain, N_len = 9, 9\n",
    "max_seq_len = 10\n",
    "max_gain = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(gain, seq_len):\n",
    "    ## Generate data\n",
    "\n",
    "    # Define problem and data encoding\n",
    "    symbols = [0, 1]\n",
    "    encoding = OneHot(symbols)\n",
    "    problem = lambda seq: np.sum(seq) % 2  # XOR problem\n",
    "\n",
    "    # Define sequence lengths for training and validation datasets\n",
    "    train_seq_lengths = list(range(1, seq_len + 1))\n",
    "    val_seq_length = 100\n",
    "    val_datapoints = 30\n",
    "    analysis_seq_lengths = list(range(1, max_seq_len+1))\n",
    "\n",
    "    # Generate datasets\n",
    "    training_datasets = [\n",
    "        seq_data(device, problem, encoding, seq_len=length)\n",
    "        for length in train_seq_lengths\n",
    "    ]\n",
    "    validation_datasets = [\n",
    "        seq_data(\n",
    "            device,\n",
    "            problem,\n",
    "            encoding,\n",
    "            n_datapoints=val_datapoints,\n",
    "            seq_len=val_seq_length,\n",
    "        )\n",
    "    ]\n",
    "    analysis_data = [\n",
    "        seq_data(device, problem, encoding, seq_len=length)\n",
    "        for length in analysis_seq_lengths\n",
    "    ]\n",
    "    tracked_datasets = validation_datasets + analysis_data + training_datasets\n",
    "\n",
    "    ## Instantiate model\n",
    "    model = Model(\n",
    "        encoding=encoding,\n",
    "        input_size=2,\n",
    "        output_size=2,\n",
    "        hidden_dim=P,\n",
    "        n_layers=L,\n",
    "        device=device,\n",
    "        nonlinearity=nonlinearity,\n",
    "        gain=gain,\n",
    "    )\n",
    "\n",
    "    ## Setup compiler\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=lr, amsgrad=True, weight_decay=0\n",
    "    )\n",
    "    compiler = Compiler(model, criterion, optimizer)\n",
    "    compiler.trackers = {\n",
    "        \"loss\": ScalarTracker(lambda: compiler.validation(tracked_datasets)),\n",
    "    }\n",
    "\n",
    "    ## Training run\n",
    "    compiler.training_run(\n",
    "        training_datasets,\n",
    "        n_epochs=n_epochs,\n",
    "        batch_size=128,\n",
    "        progress_bar=False,\n",
    "    )\n",
    "\n",
    "    ## Collect data\n",
    "    loss = compiler.trackers[\"loss\"].get_trace()\n",
    "    val_loss = loss.query(\"Dataset==0\")[0].to_numpy()[-1]\n",
    "    train_loss = loss.query(\"Dataset>0\").groupby(\"Epoch\").mean().to_numpy()[-1]\n",
    "    initial_hidden = model.init_hidden(batch_size=1)[-1]\n",
    "    hidden_function = lambda inputs: model(inputs)[1][-1]\n",
    "    output_function = lambda inputs: model(inputs)[0]\n",
    "    automaton = to_automaton(\n",
    "        hidden_function,\n",
    "        output_function,\n",
    "        initial_hidden,\n",
    "        analysis_data,\n",
    "        encoding,\n",
    "        merge_distance_frac=0.1,\n",
    "    )\n",
    "    n_states = len(automaton.states)\n",
    "    is_finite = automaton.is_finite()\n",
    "    n_exit = sum(\n",
    "        not has_all_transitions(state, automaton.transition_function)\n",
    "        for state in automaton.states\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(validation_datasets[0], batch_size=128)\n",
    "    correct = 0\n",
    "    for x, y in val_loader:\n",
    "        predictions = torch.argmax(model(x)[0], axis=1)\n",
    "        targets = torch.argmax(y, axis=1)\n",
    "        correct += sum(predictions == targets)\n",
    "    val_acc = (correct / len(validation_datasets[0])).item()\n",
    "\n",
    "    return train_loss, val_loss, val_acc,n_states, is_finite, n_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = np.linspace(0.1, max_gain, N_gain)\n",
    "seq_lens = np.linspace(2, max_seq_len, N_len, dtype=int)\n",
    "gain_data, seq_len_data, train_loss_data, val_loss_data,val_acc_data, n_states_data, is_finite_data, n_exit_data = [ [] for _ in range(8) ]\n",
    "\n",
    "for gain in tqdm(gains):\n",
    "    for seq_len in seq_lens:\n",
    "\n",
    "        train_loss, val_loss, val_acc,n_states, is_finite, n_exit = trial(gain, seq_len)\n",
    "        for data, item in zip(\n",
    "            (gain_data, seq_len_data, train_loss_data, val_loss_data,val_acc_data, n_states_data, is_finite_data, n_exit_data),\n",
    "            (gain, seq_len, train_loss, val_loss,val_acc, n_states, is_finite, n_exit),\n",
    "        ):\n",
    "            data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, name in zip(\n",
    "    (gain_data, seq_len_data, train_loss_data, val_loss_data,val_acc_data, n_states_data, is_finite_data, n_exit_data),\n",
    "    (\"gain\", \"seq_len\", \"train_loss\", \"val_loss\",\"val_acc\", \"n_states\", \"is_finite\", \"n_exit\"),\n",
    "):\n",
    "    np.save(\"plots/\" + name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states_total = np.array([sum(2**i for i in range(len+1)) for len in seq_len_data])\n",
    "n_states_norm = n_states_data/n_states_total\n",
    "\n",
    "## Plot results\n",
    "# publication.set_color_gradient(2)\n",
    "\n",
    "train_loss_grid = np.array(train_loss_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(train_loss_grid)\n",
    "plt.xlabel(\"Max training sequence length\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "# publication.im_show(colorbar=True, x_labels=seq_lens,y_labels=np.around(gains, 1),save_path=\"plots/train_loss_grid\")\n",
    "\n",
    "val_loss_grid = np.array(val_loss_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(val_loss_grid)\n",
    "plt.xlabel(\"Max training sequence length\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "# publication.im_show(colorbar=True, x_labels=seq_lens,y_labels=np.around(gains, 1),save_path=\"plots/val_loss_grid\")\n",
    "\n",
    "val_acc_grid = np.array(val_acc_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(val_acc_grid)\n",
    "plt.xlabel(\"Max training sequence length\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "# publication.im_show(colorbar=True, x_labels=seq_lens,y_labels=np.around(gains, 1),save_path=\"plots/val_acc_grid\")\n",
    "\n",
    "n_states_grid = np.array(n_states_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(n_states_grid)\n",
    "plt.xlabel(\"Max training sequence length\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "# publication.im_show(colorbar=True, x_labels=seq_lens,y_labels=np.around(gains, 1),save_path=\"plots/n_states_grid\")\n",
    "\n",
    "n_exit_grid = np.array(n_exit_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(n_exit_grid)\n",
    "plt.xlabel(\"Max training sequence length\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "# publication.im_show(colorbar=True, x_labels=seq_lens,y_labels=np.around(gains, 1),save_path=\"plots/n_exit_grid\")\n",
    "\n",
    "is_finite_grid = np.array(is_finite_data).reshape(N_gain, N_len)\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.imshow(is_finite_grid)\n",
    "plt.xlabel(\"Max training sequence length\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "# publication.im_show(colorbar=True, x_labels=seq_lens,y_labels=np.around(gains, 1),save_path=\"plots/is_finite_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(n_states_data, val_acc_data)\n",
    "publication.pub_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gain_data,\n",
    "    seq_len_data,\n",
    "    train_loss_data,\n",
    "    val_loss_data,\n",
    "    val_acc_data,\n",
    "    n_states_data,\n",
    "    is_finite_data,\n",
    "    n_exit_data,\n",
    ") = [\n",
    "    np.load(f\"plots/{name}.npy\")\n",
    "    for name in (\n",
    "        \"gain\",\n",
    "        \"seq_len\",\n",
    "        \"train_loss\",\n",
    "        \"val_loss\",\n",
    "        \"val_acc\",\n",
    "        \"n_states\",\n",
    "        \"is_finite\",\n",
    "        \"n_exit\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_structure",
   "language": "python",
   "name": "rnn_structure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e02af9847f8f14625728f2f7147d07d87bda9043f1b0a8cf0822fa7c64756065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
