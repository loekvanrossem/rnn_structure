{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8491a2ccd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "\n",
    "from data import seq_data\n",
    "from preprocessing import OneHot\n",
    "from compilation import Compiler, ScalarTracker\n",
    "from data_analysis.automata import (\n",
    "    reduce_automaton,\n",
    "    to_automaton,\n",
    "    has_all_transitions,\n",
    "    gen_rand_automaton,\n",
    ")\n",
    "\n",
    "from model import Model\n",
    "\n",
    "import publication\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, L = 100, 1\n",
    "\n",
    "N_gain, N_p = 20, 20\n",
    "max_seq_len = 10\n",
    "max_gain = 0.5\n",
    "max_p = 1\n",
    "\n",
    "n_epochs = 1000000\n",
    "\n",
    "# Define problem and data encoding\n",
    "symbols = [0, 1]\n",
    "encoding = OneHot(symbols)\n",
    "\n",
    "# # ReLU\n",
    "problem = lambda seq: np.sum(seq) % 2\n",
    "lr = 0.02\n",
    "nonlinearity = \"relu\"\n",
    "\n",
    "# tanh\n",
    "# problem = lambda seq: np.sum(seq) % 2\n",
    "# lr = 0.03\n",
    "# nonlinearity = \"tanh\"\n",
    "\n",
    "# Random\n",
    "# automaton_problem = gen_rand_automaton(symbols, [[1, 0], [0, 1]], 7, 0.6)\n",
    "# problem = lambda seq: int(np.argmax(automaton_problem.compute(seq)))\n",
    "# display_automata(reduce_automaton(automaton_problem))\n",
    "# plt.savefig(\"plots/automaton.pdf\",format=\"pdf\")\n",
    "# lr = 0.02\n",
    "# nonlinearity = \"relu\"\n",
    "\n",
    "\n",
    "# Define sequence lengths for training and validation datasets\n",
    "train_seq_lengths = list(range(1, max_seq_len + 1))\n",
    "val_seq_length = 100\n",
    "val_datapoints = 30\n",
    "analysis_seq_lengths = list(range(1, max_seq_len + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(gain, p):\n",
    "    ## Generate data\n",
    "\n",
    "    # Generate datasets\n",
    "    training_datasets = []\n",
    "    for length in range(1, max_seq_len + 1):\n",
    "        n = np.random.binomial(2**length, p)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        data = seq_data(device, problem, encoding, seq_len=length, n_datapoints=n)\n",
    "        training_datasets.append(data)\n",
    "    validation_datasets = [\n",
    "        seq_data(\n",
    "            device,\n",
    "            problem,\n",
    "            encoding,\n",
    "            n_datapoints=val_datapoints,\n",
    "            seq_len=val_seq_length,\n",
    "        )\n",
    "    ]\n",
    "    analysis_data = [\n",
    "        seq_data(device, problem, encoding, seq_len=length)\n",
    "        for length in analysis_seq_lengths\n",
    "    ]\n",
    "    tracked_datasets = validation_datasets + training_datasets\n",
    "\n",
    "    ## Instantiate model\n",
    "    model = Model(\n",
    "        encoding=encoding,\n",
    "        input_size=2,\n",
    "        output_size=2,\n",
    "        hidden_dim=P,\n",
    "        n_layers=L,\n",
    "        device=device,\n",
    "        nonlinearity=nonlinearity,\n",
    "        gain=gain,\n",
    "    )\n",
    "\n",
    "    ## Setup compiler\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0)\n",
    "    compiler = Compiler(model, criterion, optimizer)\n",
    "    compiler.trackers = {\n",
    "        \"loss\": ScalarTracker(lambda: compiler.validation(tracked_datasets)),\n",
    "    }\n",
    "\n",
    "    ## Training run\n",
    "    compiler.training_run(\n",
    "        training_datasets,\n",
    "        n_epochs=n_epochs,\n",
    "        batch_size=128,\n",
    "        progress_bar=False,\n",
    "        conv_thresh=0.001,\n",
    "    )\n",
    "\n",
    "    ## Collect data\n",
    "    loss = compiler.trackers[\"loss\"].get_trace()\n",
    "    val_loss = loss.query(\"Dataset==0\")[0].to_numpy()[-1]\n",
    "    train_loss = loss.query(\"Dataset>0\").groupby(\"Epoch\").mean().to_numpy()[-1]\n",
    "    initial_hidden = model.init_hidden(batch_size=1)[-1]\n",
    "    hidden_function = lambda inputs: model(inputs)[1][-1]\n",
    "    output_function = lambda inputs: model(inputs)[0]\n",
    "    automaton = to_automaton(\n",
    "        hidden_function,\n",
    "        output_function,\n",
    "        initial_hidden,\n",
    "        analysis_data,\n",
    "        encoding,\n",
    "        merge_distance_frac=0.1,\n",
    "    )\n",
    "    n_states = len(automaton.states)\n",
    "    is_finite = automaton.is_finite()\n",
    "    n_exit = sum(\n",
    "        not has_all_transitions(state, automaton.transition_function)\n",
    "        for state in automaton.states\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(validation_datasets[0], batch_size=128)\n",
    "    correct = 0\n",
    "    for x, y in val_loader:\n",
    "        predictions = torch.argmax(model(x)[0], axis=1)\n",
    "        targets = torch.argmax(y, axis=1)\n",
    "        correct += sum(predictions == targets)\n",
    "    val_acc = (correct / len(validation_datasets[0])).item()\n",
    "\n",
    "    return train_loss, val_loss, val_acc, n_states, is_finite, n_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "gains = np.linspace(0.1, max_gain, N_gain)\n",
    "seq_lens = np.linspace(0.1, max_p, N_p)\n",
    "(\n",
    "    gain_data,\n",
    "    seq_len_data,\n",
    "    train_loss_data,\n",
    "    val_loss_data,\n",
    "    val_acc_data,\n",
    "    n_states_data,\n",
    "    is_finite_data,\n",
    "    n_exit_data,\n",
    ") = [[] for _ in range(8)]\n",
    "\n",
    "for gain in tqdm(gains):\n",
    "    for seq_len in seq_lens:\n",
    "\n",
    "        train_loss, val_loss, val_acc, n_states, is_finite, n_exit = trial(\n",
    "            gain, seq_len\n",
    "        )\n",
    "        for data, item in zip(\n",
    "            (\n",
    "                gain_data,\n",
    "                seq_len_data,\n",
    "                train_loss_data,\n",
    "                val_loss_data,\n",
    "                val_acc_data,\n",
    "                n_states_data,\n",
    "                is_finite_data,\n",
    "                n_exit_data,\n",
    "            ),\n",
    "            (gain, seq_len, train_loss, val_loss, val_acc, n_states, is_finite, n_exit),\n",
    "        ):\n",
    "            data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, name in zip(\n",
    "    (\n",
    "        gain_data,\n",
    "        seq_len_data,\n",
    "        train_loss_data,\n",
    "        val_loss_data,\n",
    "        val_acc_data,\n",
    "        n_states_data,\n",
    "        is_finite_data,\n",
    "        n_exit_data,\n",
    "    ),\n",
    "    (\n",
    "        \"gain\",\n",
    "        \"seq_len\",\n",
    "        \"train_loss\",\n",
    "        \"val_loss\",\n",
    "        \"val_acc\",\n",
    "        \"n_states\",\n",
    "        \"is_finite\",\n",
    "        \"n_exit\",\n",
    "    ),\n",
    "):\n",
    "    np.save(\"plots/\" + name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "publication.set_color_gradient(2)\n",
    "\n",
    "x_labels = np.around(seq_lens, 1)\n",
    "y_labels = np.around(gains, 1)\n",
    "\n",
    "x_labels = [l if n % 2 == 0 else None for n, l in enumerate(x_labels)]\n",
    "y_labels = [l if n % 2 == 0 else None for n, l in enumerate(y_labels)]\n",
    "\n",
    "\n",
    "val_acc_grid = np.array(val_acc_data).reshape(N_gain, N_p)\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(val_acc_grid)\n",
    "plt.xlabel(\"Training data fraction\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "publication.im_show(\n",
    "    colorbar=True,\n",
    "    x_labels=x_labels,\n",
    "    y_labels=y_labels,\n",
    "    save_path=\"plots/val_acc_grid\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "n_states_grid = np.array(n_states_data).reshape(N_gain, N_p)\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(n_states_grid)\n",
    "plt.xlabel(\"Training data fraction\")\n",
    "plt.ylabel(\"Initial weight scale\")\n",
    "publication.im_show(\n",
    "    colorbar=True,\n",
    "    x_labels=x_labels,\n",
    "    y_labels=y_labels,\n",
    "    save_path=\"plots/n_states_grid\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gain_data,\n",
    "    seq_len_data,\n",
    "    train_loss_data,\n",
    "    val_loss_data,\n",
    "    val_acc_data,\n",
    "    n_states_data,\n",
    "    is_finite_data,\n",
    "    n_exit_data,\n",
    ") = [\n",
    "    np.load(f\"plots/{name}.npy\")\n",
    "    for name in (\n",
    "        \"gain\",\n",
    "        \"seq_len\",\n",
    "        \"train_loss\",\n",
    "        \"val_loss\",\n",
    "        \"val_acc\",\n",
    "        \"n_states\",\n",
    "        \"is_finite\",\n",
    "        \"n_exit\",\n",
    "    )\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_structure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
