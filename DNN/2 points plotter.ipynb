{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from tqdm import trange, tqdm\n",
    "from IPython.utils import io\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numba import njit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "from data import fun_data, grid_data\n",
    "from preprocessing import Direct, Encoding, OneHot\n",
    "from compilation import Compiler, Tracker, ScalarTracker, ActivationTracker\n",
    "from activations import get_activations\n",
    "from data_analysis.automata import to_automaton_history\n",
    "from data_analysis.visualization.animation import SliderAnimation\n",
    "from data_analysis.visualization.activations import (\n",
    "    ActivationsAnimation,\n",
    "    FunctionAnimation,\n",
    "    PointAnimation,\n",
    ")\n",
    "from data_analysis.visualization.automata import AutomatonAnimation\n",
    "from data_analysis.visualization.epochs import EpochAnimation\n",
    "from data_analysis.visualization.publication import pub_show\n",
    "from simulate import rep_sim, der, optimize_eta\n",
    "\n",
    "import models as models\n",
    "from models import MLP, CNN, ResNet\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    pub_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = pd.read_csv(\"model_settings/2 points.txt\", sep=\" \", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(setting, save=True):\n",
    "    ## Load settings\n",
    "    (\n",
    "        model_type,\n",
    "        nonlinearity,\n",
    "        gain,\n",
    "        lr,\n",
    "        P,\n",
    "        L,\n",
    "        n_epochs,\n",
    "        hidden_layer,\n",
    "        dx2,\n",
    "        dy2,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "        eta_guess,\n",
    "    ) = settings.loc[setting].to_numpy()\n",
    "    model_type = getattr(models, model_type)\n",
    "    nonlinearity = getattr(torch.nn.functional, nonlinearity)\n",
    "\n",
    "    ## Generate data\n",
    "    input_dim, output_dim = in_dim, out_dim\n",
    "\n",
    "    inputs = np.array([[-1] * input_dim, [-1 + np.sqrt(dx2)] * input_dim]) / np.sqrt(\n",
    "        input_dim\n",
    "    )\n",
    "    outputs = np.array(\n",
    "        [[0.6] * output_dim, [0.6 + np.sqrt(dy2)] * output_dim]\n",
    "    ) / np.sqrt(output_dim)\n",
    "    names = [\"A\", \"B\"]\n",
    "    data = TensorDataset(\n",
    "        torch.from_numpy(inputs.astype(np.float32)).to(device),\n",
    "        torch.from_numpy(outputs.astype(np.float32)).to(device),\n",
    "    )\n",
    "\n",
    "    encoding = Encoding(dict(zip(names, inputs)))\n",
    "\n",
    "    train_datasets = [data]\n",
    "    val_dataset = [data]\n",
    "\n",
    "    tracked_datasets = val_dataset + train_datasets\n",
    "\n",
    "    ## Instantiate model\n",
    "    model = model_type(\n",
    "        encoding=encoding,\n",
    "        input_size=inputs.shape[1],\n",
    "        output_size=outputs.shape[1],\n",
    "        hidden_dim=P,\n",
    "        n_hid_layers=L,\n",
    "        device=device,\n",
    "        init_std=gain,\n",
    "        non_linearity=nonlinearity,\n",
    "    )\n",
    "\n",
    "    ## Setup compiler\n",
    "\n",
    "    # Define Loss, Optimizer\n",
    "    criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    compiler = Compiler(model, criterion, optimizer)\n",
    "    compiler.trackers = {\n",
    "        \"loss\": ScalarTracker(lambda: compiler.validation(tracked_datasets)),\n",
    "        \"hidden\": ActivationTracker(\n",
    "            model, lambda inputs: model(inputs)[1][hidden_layer]\n",
    "        ),\n",
    "        \"output\": ActivationTracker(model, lambda inputs: model(inputs)[0]),\n",
    "    }\n",
    "\n",
    "    ## Training run\n",
    "    compiler.training_run(\n",
    "        train_datasets, tracked_datasets, n_epochs=n_epochs, batch_size=100\n",
    "    )\n",
    "\n",
    "    data_hid = compiler.trackers[\"hidden\"].get_trace()\n",
    "    data_output = compiler.trackers[\"output\"].get_trace()\n",
    "    loss = compiler.trackers[\"loss\"].get_trace().copy()\n",
    "    # val_loss = loss.query(\"Dataset==0\")[0].to_numpy()\n",
    "    train_loss = loss.groupby(\"Epoch\").mean()\n",
    "\n",
    "    h_A = [\n",
    "        np.array(data.loc[epoch, 0, \"A\"])\n",
    "        for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "    h_B = [\n",
    "        np.array(data.loc[epoch, 0, \"B\"])\n",
    "        for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "    y_A = [\n",
    "        np.array(data.loc[epoch, 0, \"A\"])\n",
    "        for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "    y_B = [\n",
    "        np.array(data.loc[epoch, 0, \"B\"])\n",
    "        for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "\n",
    "    epochs = np.arange(0, len(h_A))\n",
    "\n",
    "    y_true_A, y_true_B = outputs[0], outputs[1]\n",
    "    dy2 = np.sum((y_true_B - y_true_A) ** 2)\n",
    "    h2 = np.array([np.sum((h_A[epoch] - h_B[epoch]) ** 2) for epoch in epochs])\n",
    "    y2 = np.array([np.sum((y_A[epoch] - y_B[epoch]) ** 2) for epoch in epochs])\n",
    "    w = np.array(\n",
    "        [\n",
    "            y2[epoch] - np.dot(y_true_A - y_true_B, y_A[epoch] - y_B[epoch])\n",
    "            for epoch in epochs\n",
    "        ]\n",
    "    )\n",
    "    y0_mean = np.sum((0.5 * ((y_A[0] + y_B[0]) - (y_true_B + y_true_A))) ** 2)\n",
    "\n",
    "    h0, y0, w0, dy = h2[0], y2[0], w[0], dy2\n",
    "\n",
    "    ## Comparison\n",
    "    traj_path = \"plots/2 points/trajectories/\"\n",
    "\n",
    "    eta_h, eta_y = optimize_eta(h2, y2, w, dx2, dy2)\n",
    "\n",
    "    t_max = len(epochs)\n",
    "\n",
    "    sol = scipy.integrate.solve_ivp(\n",
    "        der, [0, t_max], [h0, y0, w0], args=(eta_h, eta_y), dense_output=True\n",
    "    )\n",
    "\n",
    "    t = np.linspace(0, t_max, len(epochs))\n",
    "    z = sol.sol(t)\n",
    "    t = epochs\n",
    "\n",
    "    dh = h2[1:] - h2[:-1]\n",
    "    loss_theory = (1 / 4) * (\n",
    "        2 * np.exp(-2 * t * eta_y) * y0_mean + z[2] + (1 / 2) * (dy - z[1])\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    plt.plot(t, z[0], linestyle=\"--\")\n",
    "    plt.plot(t, z[1], linestyle=\"--\")\n",
    "    plt.plot(t, z[2], linestyle=\"--\")\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    ax.plot(t, h2, label=\"$||dh||^2$\")\n",
    "    ax.plot(t, y2, label=\"$||dy||^2$\")\n",
    "    ax.plot(t, w, label=\"$w$\")\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if save:\n",
    "        with io.capture_output() as captured:\n",
    "            pub_show(save_path=traj_path + \"ode/\" + setting + \".png\")\n",
    "    else:\n",
    "        pub_show()\n",
    "\n",
    "    ## STIL PROPORTIAL WITHOUT FITTING\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    ax.plot(t[:-1], dh, label=r\"$\\frac{d}{dt}||dh||^2$\")\n",
    "    ax.plot(0, 0)\n",
    "    ax.plot(t, -w, label=\"$-w$\")\n",
    "    ax.legend()\n",
    "    plt.ylim()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if save:\n",
    "        with io.capture_output() as captured:\n",
    "            pub_show(save_path=traj_path + \"dh/\" + setting + \".png\")\n",
    "    else:\n",
    "        pub_show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    ax.plot(0, 0)\n",
    "    ax.plot(t, loss_theory, label=r\"loss (theory)\", linestyle=\"--\")\n",
    "    ax.plot(0, 0)\n",
    "    ax.plot(0, 0)\n",
    "    ax.plot(t, train_loss, label=\"train loss\", zorder=1)\n",
    "    ax.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if save:\n",
    "        with io.capture_output() as captured:\n",
    "            pub_show(save_path=traj_path + \"loss/\" + setting + \".png\")\n",
    "    else:\n",
    "        pub_show()\n",
    "\n",
    "    return eta_h_opt, eta_y_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t-----DEFAULT-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▎      | 325/1000 [00:02<00:05, 130.55steps/s, train_loss=0.11579, val_loss=0.11579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0028175014523431296\n",
      "\t\t\t\t\t-----GAIN_0.7-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [00:07<00:00, 142.49steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    }
   ],
   "source": [
    "etas_h, etas_y = {}, {}\n",
    "for setting in settings.index:\n",
    "    print(f\"\\t\\t\\t\\t\\t-----{setting.upper()}-----\")\n",
    "    eta_h, eta_y = make_plots(setting, save=True)\n",
    "    etas_h[setting] = eta_h\n",
    "    etas_y[setting] = eta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/loek/projects/rnn/DNN/2 points plotter.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/loek/projects/rnn/DNN/2%20points%20plotter.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m setting \u001b[39min\u001b[39;00m settings\u001b[39m.\u001b[39mindex:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/loek/projects/rnn/DNN/2%20points%20plotter.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m setting \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mdiscontinuous\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mearly_layer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlate_layer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCNN\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/loek/projects/rnn/DNN/2%20points%20plotter.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'settings' is not defined"
     ]
    }
   ],
   "source": [
    "for setting in settings.index:\n",
    "    if setting in [\"discontinuous\", \"early_layer\", \"late_layer\", \"CNN\"]:\n",
    "        continue\n",
    "    plt.scatter(etas_h[setting], etas_y[setting], label=f\"{setting}\")\n",
    "plt.legend(bbox_to_anchor=(1.5, 1))\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e02af9847f8f14625728f2f7147d07d87bda9043f1b0a8cf0822fa7c64756065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
