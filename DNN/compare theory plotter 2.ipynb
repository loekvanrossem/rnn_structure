{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from tqdm import trange, tqdm\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numba import njit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "from data import fun_data, grid_data\n",
    "from preprocessing import Direct, Encoding, OneHot\n",
    "from compilation import Compiler, Tracker, ScalarTracker, ActivationTracker\n",
    "from activations import get_activations\n",
    "from data_analysis.visualization.animation import SliderAnimation\n",
    "from data_analysis.visualization.activations import (\n",
    "    ActivationsAnimation,\n",
    "    FunctionAnimation,\n",
    "    PointAnimation,\n",
    ")\n",
    "from data_analysis.visualization.automata import AutomatonAnimation\n",
    "from data_analysis.visualization.epochs import EpochAnimation\n",
    "import data_analysis.visualization.publication as publication\n",
    "import simulate\n",
    "import two_points\n",
    "\n",
    "import models as models\n",
    "from models import MLP, CNN, ResNet\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "traj_path = \"plots/2_points/comparisons/\"\n",
    "\n",
    "publication.set_color_mixed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = pd.read_csv(\"model_settings/2 points.txt\", sep=\" \", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(setting, save=True):\n",
    "    ## Load settings\n",
    "    (\n",
    "        model_type,\n",
    "        nonlinearity,\n",
    "        gain,\n",
    "        lr,\n",
    "        P,\n",
    "        L,\n",
    "        n_epochs,\n",
    "        hidden_layer,\n",
    "        dx2,\n",
    "        dy2,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "    ) = settings.loc[setting].to_numpy()\n",
    "    model_type = getattr(models, model_type)\n",
    "    if nonlinearity == \"discontinuous\":\n",
    "        nonlinearity = simulate.Discontinuous.apply\n",
    "    elif nonlinearity == \"none\":\n",
    "        nonlinearity = None\n",
    "    else:\n",
    "        nonlinearity = getattr(torch.nn.functional, nonlinearity)\n",
    "\n",
    "    threshold = 1e-4\n",
    "    n_epochs_plot = 40000\n",
    "\n",
    "    figsize = (2,2)\n",
    "\n",
    "    ## Load data\n",
    "    def load_data(data_name):\n",
    "        data_path = f\"{traj_path}{data_name}.pkl\"\n",
    "        if os.path.exists(data_path):\n",
    "            with open(data_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    etas_h_dic, etas_y_dic, G_hs_dic, G_ys_dic = [\n",
    "        load_data(name) for name in [\"etas_h\", \"etas_y\", \"G_hs\", \"G_ys\"]\n",
    "    ]\n",
    "\n",
    "    if setting in etas_h_dic.keys():\n",
    "        eta_h_opts = etas_h_dic[setting]\n",
    "        eta_y_opts = etas_y_dic[setting]\n",
    "        G_hs = G_hs_dic[setting]\n",
    "        G_ys = G_ys_dic[setting]\n",
    "        print(\"Fit parameters succesfully loaded from previous run.\")\n",
    "    else:\n",
    "        ## Fit effective learning rates\n",
    "        print(\"Could not find previous fit parameters, fitting...\")\n",
    "        eta_h_opts, eta_y_opts = [], []\n",
    "        G_hs, G_ys = [], []\n",
    "        for _ in range(50):\n",
    "            data, encoding = two_points.data_set(dx2, dy2, 1, 1, device)\n",
    "\n",
    "            model = model_type(\n",
    "                encoding=encoding,\n",
    "                input_size=1,\n",
    "                output_size=1,\n",
    "                hidden_dim=P,\n",
    "                n_hid_layers=L,\n",
    "                device=device,\n",
    "                init_std=gain,\n",
    "                non_linearity=nonlinearity,\n",
    "            )\n",
    "\n",
    "            # Compute G\n",
    "            input_1 = data[0][0]\n",
    "            input_2 = data[0][1]\n",
    "            hid_1 = model(input_1)[1][hidden_layer]\n",
    "            hid_2 = model(input_2)[1][hidden_layer]\n",
    "            pred_1 = model(input_1)[0]\n",
    "            pred_2 = model(input_2)[0]\n",
    "            input_1, input_2, hid_1, hid_2, pred_1, pred_2 = [\n",
    "                a.detach().numpy()\n",
    "                for a in (input_1, input_2, hid_1, hid_2, pred_1, pred_2)\n",
    "            ]\n",
    "            G_h = (\n",
    "                np.linalg.norm(hid_2 - hid_1) ** 2\n",
    "                / np.linalg.norm(input_2 - input_1) ** 2\n",
    "            )\n",
    "            G_y = (\n",
    "                np.linalg.norm(pred_2 - pred_1) ** 2\n",
    "                / np.linalg.norm(hid_2 - hid_1) ** 2\n",
    "            )\n",
    "\n",
    "            criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr/2)\n",
    "            compiler = Compiler(model, criterion, optimizer)\n",
    "            compiler.trackers = {\n",
    "                \"loss\": ScalarTracker(lambda: compiler.validation([data])),\n",
    "                \"hidden\": ActivationTracker(\n",
    "                    model,\n",
    "                    lambda inputs: model(inputs)[1][hidden_layer],\n",
    "                    datasets=[data],\n",
    "                ),\n",
    "                \"output\": ActivationTracker(\n",
    "                    model, lambda inputs: model(inputs)[0], datasets=[data]\n",
    "                ),\n",
    "            }\n",
    "\n",
    "            h0, y0, w0 = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "\n",
    "            with io.capture_output() as captured:\n",
    "                compiler.training_run([data], [data], n_epochs=2*n_epochs, batch_size=100)\n",
    "\n",
    "            if compiler.trackers[\"loss\"].get_entry(-1)[0][0] > 1e-2:\n",
    "                continue\n",
    "\n",
    "            data_hid = compiler.trackers[\"hidden\"].get_trace().copy()\n",
    "            data_output = compiler.trackers[\"output\"].get_trace().copy()\n",
    "            h_A = [\n",
    "                np.array(data.loc[epoch, 0, \"A\"])\n",
    "                for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            h_B = [\n",
    "                np.array(data.loc[epoch, 0, \"B\"])\n",
    "                for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            y_A = [\n",
    "                np.array(data.loc[epoch, 0, \"A\"])\n",
    "                for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            y_B = [\n",
    "                np.array(data.loc[epoch, 0, \"B\"])\n",
    "                for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            epochs = np.arange(0, len(h_A))\n",
    "            y_true_A, y_true_B = data[0][1].numpy(), data[1][1].numpy()\n",
    "            dy2 = np.sum((y_true_B - y_true_A) ** 2)\n",
    "            h2 = np.array([np.sum((h_A[epoch] - h_B[epoch]) ** 2) for epoch in epochs])\n",
    "            y2 = np.array([np.sum((y_A[epoch] - y_B[epoch]) ** 2) for epoch in epochs])\n",
    "            w = np.array(\n",
    "                [\n",
    "                    y2[epoch] - np.dot(y_true_A - y_true_B, y_A[epoch] - y_B[epoch])\n",
    "                    for epoch in epochs\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            eta_h_opt, eta_y_opt, fit_loss = simulate.optimize_eta(h2, y2, w, dx2, dy2)\n",
    "\n",
    "            if fit_loss > 1:\n",
    "                continue\n",
    "\n",
    "            G_hs.append(G_h)\n",
    "            G_ys.append(G_y)\n",
    "            eta_h_opts.append(eta_h_opt)\n",
    "            eta_y_opts.append(eta_y_opt)\n",
    "\n",
    "        ## Save data\n",
    "        datas = [eta_h_opts, eta_y_opts, G_hs, G_ys]\n",
    "        data_dics = [etas_h_dic, etas_y_dic, G_hs_dic, G_ys_dic]\n",
    "        data_names = [\"etas_h\", \"etas_y\", \"G_hs\", \"G_ys\"]\n",
    "        for data, data_dic in zip(datas, data_dics):\n",
    "            data_dic[setting] = data\n",
    "\n",
    "        for data_dic, data_name in zip(data_dics, data_names):\n",
    "            data_path = f\"{traj_path}{data_name}.pkl\"\n",
    "            with open(data_path, \"wb\") as f:\n",
    "                pickle.dump(data_dic, f)\n",
    "\n",
    "    eta_h, eta_y = np.mean(eta_h_opts), np.mean(eta_y_opts)\n",
    "    G_h, G_y = np.mean(G_hs), np.mean(G_ys)\n",
    "\n",
    "    print(f\"eta_h, eta_y, G_h, G_y = {eta_h}, {eta_y}, {G_h}, {G_y}\")\n",
    "\n",
    "    h0s, y0s, w0s, hs, ys, ws = [], [], [], [], [], []\n",
    "    dx2s, dy2s = [], []\n",
    "\n",
    "    N = 5\n",
    "    m = 1\n",
    "\n",
    "    print(\"Computing comparison...\")\n",
    "    for dx in np.linspace(1, 2, N):\n",
    "        for dy in np.linspace(0, 1, N):\n",
    "            dx2 = dx**2\n",
    "            dy2 = dy**2\n",
    "            variables = []\n",
    "            for _ in range(m):\n",
    "                ## Generate data\n",
    "                data, encoding = two_points.data_set(dx2, dy2, 1, 1, device)\n",
    "    \n",
    "                ## Instantiate model\n",
    "                model = model_type(\n",
    "                    encoding=encoding,\n",
    "                    input_size=1,\n",
    "                    output_size=1,\n",
    "                    hidden_dim=P,\n",
    "                    n_hid_layers=L,\n",
    "                    device=device,\n",
    "                    init_std=gain,\n",
    "                    non_linearity=nonlinearity,\n",
    "                )\n",
    "    \n",
    "                criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr=lr / 5)\n",
    "                compiler = Compiler(model, criterion, optimizer)\n",
    "                compiler.trackers = {\n",
    "                    \"loss\": ScalarTracker(lambda: compiler.validation([data]))\n",
    "                }\n",
    "    \n",
    "                h0, y0, w0 = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "    \n",
    "                ## Training run\n",
    "                with io.capture_output() as captured:\n",
    "                    compiler.training_run(\n",
    "                        [data],\n",
    "                        [],\n",
    "                        n_epochs=n_epochs_plot,\n",
    "                        batch_size=100,\n",
    "                        conv_thresh=threshold,\n",
    "                    )\n",
    "\n",
    "                if compiler.trackers[\"loss\"].get_entry(-1)[0][0] > 1e-3:\n",
    "                    break\n",
    "    \n",
    "                h, y, w = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "    \n",
    "                variables.append([h0, y0, w0, h, y, w])\n",
    "    \n",
    "            if len(variables) > 0:\n",
    "                variables = np.mean(np.array(variables), axis=0)\n",
    "                for i, array in enumerate((h0s, y0s, w0s, hs, ys, ws)):\n",
    "                    array.append(variables[i])\n",
    "                dx2s.append(dx2)\n",
    "                dy2s.append(dy2)\n",
    "    \n",
    "                clear_output(wait=True)\n",
    "\n",
    "                publication.set_color_mixed()\n",
    "                A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2s) * np.sqrt(dx2s)\n",
    "                A_high = (\n",
    "                    np.array(h0s) / np.array(dx2s)\n",
    "                    - np.array(y0s) / np.array(h0s) * eta_h / eta_y\n",
    "                ) * np.array(dx2s)\n",
    "                h_theory = 0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2)\n",
    "                fig = plt.figure(figsize=figsize)\n",
    "                plt.scatter(h_theory, hs)\n",
    "                plt.xlabel(\"$||dh(\\infty)||^2$ (Theory)\")\n",
    "                plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "                plt.ylim(0, 1.1 * max(hs))\n",
    "                plt.xlim(0)\n",
    "                plt.scatter(-1,-1)\n",
    "                plt.plot(np.sort(h_theory), np.sort(h_theory), linestyle=\"--\", color=\"0.6\",zorder=0)\n",
    "                publication.plt_show()\n",
    "\n",
    "    ## Plot theory\n",
    "    publication.set_color_mixed()\n",
    "    A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2s) * np.sqrt(dx2s)\n",
    "    A_high = (\n",
    "        np.array(h0s) / np.array(dx2s)\n",
    "        - np.array(y0s) / np.array(h0s) * eta_h / eta_y\n",
    "    ) * np.array(dx2s)\n",
    "    h_theory = 0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(h_theory, hs)\n",
    "    plt.xlabel(\"$||dh(\\infty)||^2$ (Theory)\")\n",
    "    plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "    plt.ylim(0, 1.1 * max(hs))\n",
    "    plt.xlim(0)\n",
    "    publication.plt_show(\n",
    "        save_path=traj_path + \"dh_vs_theory_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    ## Plot theory with line\n",
    "    publication.set_color_mixed()\n",
    "    A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2s) * np.sqrt(dx2s)\n",
    "    A_high = (\n",
    "        np.array(h0s) / np.array(dx2s)\n",
    "        - np.array(y0s) / np.array(h0s) * eta_h / eta_y\n",
    "    ) * np.array(dx2s)\n",
    "    h_theory = 0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(h_theory, hs)\n",
    "    plt.xlabel(\"$||dh(\\infty)||^2$ (Theory)\")\n",
    "    plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "    plt.ylim(0, 1.1 * max(hs))\n",
    "    plt.xlim(0)\n",
    "    plt.scatter(-1,-1)\n",
    "    plt.plot(np.sort(h_theory), np.sort(h_theory), linestyle=\"--\", color=\"0.6\",zorder=0)\n",
    "    publication.plt_show(\n",
    "        save_path=traj_path + \"dh_vs_theory_line_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    ## Plot dx\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(np.array(dx2s), hs)\n",
    "    plt.xlabel(\"$||x_2-x_1||^2$\")\n",
    "    plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "    plt.ylim(0, 1.1 * max(hs))\n",
    "    plt.xlim(0)\n",
    "    publication.plt_show(\n",
    "        save_path=traj_path + \"dh_vs_x_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    ## Plot dy\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(np.array(dy2s), hs)\n",
    "    plt.xlabel(\"$||y_2-y_1||^2$\")\n",
    "    plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "    plt.ylim(0, 1.1 * max(hs))\n",
    "    plt.xlim(0)\n",
    "    publication.plt_show(\n",
    "        save_path=traj_path + \"dh_vs_y_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    ## Plot h0\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(np.array(h0s), hs)\n",
    "    plt.xlabel(\"$||dh(0)||^2$\")\n",
    "    plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "    plt.ylim(0, 1.1 * max(hs))\n",
    "    plt.xlim(0)\n",
    "    publication.plt_show(\n",
    "        save_path=traj_path + \"dh_vs_h0_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    ## Plot y0\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(np.array(y0s), hs)\n",
    "    plt.xlabel(\"$||dy(0)||^2$\")\n",
    "    plt.ylabel(\"$||dh(\\infty)||^2$\")\n",
    "    plt.ylim(0, 1.1 * max(hs))\n",
    "    plt.xlim(0)\n",
    "    publication.plt_show(\n",
    "        save_path=traj_path + \"dh_vs_y0_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    return eta_h_opts, eta_y_opts, G_hs, G_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas_h, etas_y, G_hs, G_ys = {}, {}, {}, {}\n",
    "for setting in settings.index:\n",
    "    print(f\"\\t\\t\\t\\t\\t-----{setting.upper()}-----\")\n",
    "    eta_h_opts, eta_y_opts, G_h, G_y = make_plots(setting, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN",
   "language": "python",
   "name": "rnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
