{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from tqdm import trange, tqdm\n",
    "from IPython.utils import io\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numba import njit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "import wandb\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "from data import fun_data, grid_data\n",
    "from preprocessing import Direct, Encoding, OneHot\n",
    "from compilation import Compiler, Tracker, ScalarTracker, ActivationTracker\n",
    "from activations import get_activations\n",
    "from data_analysis.automata import to_automaton_history\n",
    "from data_analysis.visualization.animation import SliderAnimation\n",
    "from data_analysis.visualization.activations import (\n",
    "    ActivationsAnimation,\n",
    "    FunctionAnimation,\n",
    "    PointAnimation,\n",
    ")\n",
    "from data_analysis.visualization.automata import AutomatonAnimation\n",
    "from data_analysis.visualization.epochs import EpochAnimation\n",
    "import data_analysis.visualization.publication as publication\n",
    "import simulate\n",
    "import two_points\n",
    "\n",
    "import models as models\n",
    "from models import MLP, CNN, ResNet\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load settings\n",
    "settings = \"default\"\n",
    "\n",
    "(\n",
    "    model_type,\n",
    "    nonlinearity,\n",
    "    gain,\n",
    "    lr,\n",
    "    P,\n",
    "    L,\n",
    "    n_epochs,\n",
    "    hidden_layer,\n",
    "    dx2,\n",
    "    dy2,\n",
    "    in_dim,\n",
    "    out_dim,\n",
    ") = (\n",
    "    pd.read_csv(\"model_settings/2 points.txt\", sep=\" \", header=0)\n",
    "    .loc[settings]\n",
    "    .to_numpy()\n",
    ")\n",
    "model_type = getattr(models, model_type)\n",
    "if nonlinearity == \"discontinuous\":\n",
    "    nonlinearity = simulate.Discontinuous.apply\n",
    "elif nonlinearity == \"none\":\n",
    "    nonlinearity = None\n",
    "else:\n",
    "    nonlinearity = getattr(torch.nn.functional, nonlinearity)\n",
    "\n",
    "mod = 1\n",
    "# factor = 0.25\n",
    "# n_epochs = int(factor * n_epochs)\n",
    "# lr = lr / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate data\n",
    "\n",
    "input_dim, output_dim = 1, 1\n",
    "\n",
    "# data, encoding = two_points.data_set(dx2, dy2, input_dim, output_dim, device)\n",
    "\n",
    "inputs = np.array([[-1] * input_dim, [-1 + np.sqrt(dx2)] * input_dim]) / np.sqrt(\n",
    "    input_dim\n",
    ")\n",
    "outputs = np.array([[0.6] * output_dim, [0.6 + np.sqrt(dy2)] * output_dim]) / np.sqrt(\n",
    "    output_dim\n",
    ")\n",
    "names = [\"A\", \"B\"]\n",
    "data = TensorDataset(\n",
    "    torch.from_numpy(inputs.astype(np.float32)).to(device),\n",
    "    torch.from_numpy(outputs.astype(np.float32)).to(device),\n",
    ")\n",
    "\n",
    "encoding = Encoding(dict(zip(names, inputs)))\n",
    "\n",
    "train_datasets = [data]\n",
    "val_dataset = [data]\n",
    "\n",
    "tracked_datasets = val_dataset + train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:21<00:00, 137.63steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.7920787930488586\n",
      "y0: 0.026708265766501427\n",
      "w0: 0.14226834947500516\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/29 [00:33<15:34, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06347797557158782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:22<00:00, 131.19steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.5775344371795654\n",
      "y0: 0.00019407583749853075\n",
      "w0: -0.009656706867422305\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/29 [01:02<13:53, 30.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.32555788169532984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:23<00:00, 126.80steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.5677255988121033\n",
      "y0: 2.8383142307575326e-06\n",
      "w0: -0.0011884454870160753\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/29 [01:37<14:06, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19156300928327835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:34<00:00, 87.89steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.29200783371925354\n",
      "y0: 0.00013796288112644106\n",
      "w0: 0.00844346958097681\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [02:14<14:22, 34.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.27177577802851566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:36<00:00, 81.88steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.19714519381523132\n",
      "y0: 0.001283206045627594\n",
      "w0: 0.026613090581572407\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/29 [02:55<14:39, 36.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10115269760430964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:39<00:00, 76.78steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.08959214389324188\n",
      "y0: 4.094744144822471e-05\n",
      "w0: -0.004483842067183193\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [03:37<14:48, 38.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02480841126502093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:41<00:00, 71.43steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.12686318159103394\n",
      "y0: 3.446510527282953e-05\n",
      "w0: -0.00411674593341466\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7/29 [04:29<15:44, 42.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.033095321820426425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:45<00:00, 66.41steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.0793415904045105\n",
      "y0: 0.0002558072446845472\n",
      "w0: 0.011565255498074979\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [05:24<16:22, 46.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.008776110904909304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:48<00:00, 62.14steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.06489614397287369\n",
      "y0: 1.0538107744650915e-05\n",
      "w0: 0.002305980107196076\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 9/29 [06:16<16:08, 48.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.024784144416706615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:52<00:00, 57.34steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.02042507939040661\n",
      "y0: 1.5304981388908345e-06\n",
      "w0: -0.0008732546723017961\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [07:13<16:09, 51.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0014232748498424536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [00:56<00:00, 53.05steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.027690060436725616\n",
      "y0: 2.3453421249541861e-07\n",
      "w0: -0.0003422083218252964\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11/29 [08:13<16:11, 53.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05172962685890511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [01:07<00:00, 44.71steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.01497587002813816\n",
      "y0: 4.117758933830373e-08\n",
      "w0: 0.00014352913552791508\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 12/29 [09:26<16:55, 59.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00810414952046273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [01:14<00:00, 40.08steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.017987292259931564\n",
      "y0: 2.3570739813294495e-06\n",
      "w0: -0.001083247373573421\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 13/29 [10:45<17:27, 65.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03877467649921658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [01:28<00:00, 33.81steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.005935323424637318\n",
      "y0: 3.644300079486129e-07\n",
      "w0: -0.00042650206211486256\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [12:19<18:31, 74.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0010843084464671566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [01:49<00:00, 27.28steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.006096958182752132\n",
      "y0: 8.070663426451574e-08\n",
      "w0: 0.00020096205321448773\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15/29 [14:13<20:06, 86.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.024369327483640724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [01:59<00:00, 25.13steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.004306002985686064\n",
      "y0: 1.3486150862718205e-08\n",
      "w0: -8.210274374503842e-05\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 16/29 [16:17<21:09, 97.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.032511608851780296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [02:12<00:00, 22.69steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.0040100268088281155\n",
      "y0: 1.277218419915016e-08\n",
      "w0: -7.990025590121406e-05\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 17/29 [18:33<21:49, 109.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03695050569645375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3000/3000 [02:33<00:00, 19.55steps/s, train_loss=0.00000, val_loss=0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: 0.002510880120098591\n",
      "y0: 1.4511121193550025e-08\n",
      "w0: 8.519408941795053e-05\n",
      "dy: 0.5000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [21:13<22:48, 124.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05178590617640152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 567/3000 [00:35<02:32, 15.90steps/s, train_loss=0.04579, val_loss=0.04579]\n",
      " 62%|██████▏   | 18/29 [21:49<13:20, 72.76s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m\n\u001b[1;32m     24\u001b[0m compiler\u001b[38;5;241m.\u001b[39mtrackers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: ScalarTracker(\u001b[38;5;28;01mlambda\u001b[39;00m: compiler\u001b[38;5;241m.\u001b[39mvalidation(tracked_datasets)),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m\"\u001b[39m: ActivationTracker(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     ),\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m## Training run\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracked_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m data_hid \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mtrackers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_trace()\n\u001b[1;32m     45\u001b[0m data_output \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mtrackers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/projects/rnn/DNN/../source/compilation.py:220\u001b[0m, in \u001b[0;36mCompiler.training_run\u001b[0;34m(self, training_datasets, tracked_datasets, n_epochs, batch_size, conv_thresh)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tracker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrackers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 220\u001b[0m     \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[1;32m    223\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/projects/rnn/DNN/../source/compilation.py:110\u001b[0m, in \u001b[0;36mActivationTracker.track\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Store the data of this epoch. Should be called each epoch.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     act_this_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         initial_hidden \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    119\u001b[0m             index\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial\u001b[39m\u001b[38;5;124m\"\u001b[39m])],\n\u001b[1;32m    120\u001b[0m         )\n",
      "File \u001b[0;32m~/projects/rnn/DNN/../source/activations.py:51\u001b[0m, in \u001b[0;36mget_activations\u001b[0;34m(datasets, output_function, encoding)\u001b[0m\n\u001b[1;32m     48\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Store activities\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m act_this_dataset \u001b[38;5;241m=\u001b[39m \u001b[43moutput_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m act_this_dataset \u001b[38;5;241m=\u001b[39m act_this_dataset\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     53\u001b[0m act_this_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(act_this_dataset, labels)\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     23\u001b[0m compiler \u001b[38;5;241m=\u001b[39m Compiler(model, criterion, optimizer)\n\u001b[1;32m     24\u001b[0m compiler\u001b[38;5;241m.\u001b[39mtrackers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: ScalarTracker(\u001b[38;5;28;01mlambda\u001b[39;00m: compiler\u001b[38;5;241m.\u001b[39mvalidation(tracked_datasets)),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m\"\u001b[39m: ActivationTracker(\n\u001b[1;32m     27\u001b[0m         model,\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inputs: \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m][hidden_layer],\n\u001b[1;32m     29\u001b[0m         datasets\u001b[38;5;241m=\u001b[39mtracked_datasets,\n\u001b[1;32m     30\u001b[0m     ),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: ActivationTracker(\n\u001b[1;32m     32\u001b[0m         model, \u001b[38;5;28;01mlambda\u001b[39;00m inputs: model(inputs)[\u001b[38;5;241m0\u001b[39m], datasets\u001b[38;5;241m=\u001b[39mtracked_datasets\n\u001b[1;32m     33\u001b[0m     ),\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m## Training run\u001b[39;00m\n\u001b[1;32m     37\u001b[0m compiler\u001b[38;5;241m.\u001b[39mtraining_run(\n\u001b[1;32m     38\u001b[0m     train_datasets,\n\u001b[1;32m     39\u001b[0m     tracked_datasets,\n\u001b[1;32m     40\u001b[0m     n_epochs\u001b[38;5;241m=\u001b[39mn_epochs,\n\u001b[1;32m     41\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/rnn/DNN/models.py:71\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m activations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_linearity \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rnn/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses, Ps, Ls = [], [], []\n",
    "\n",
    "for L in trange(1, 30):\n",
    "    P = L * 50\n",
    "    hidden_layer = int(L / 2)\n",
    "\n",
    "    ## Instantiate model\n",
    "    model = model_type(\n",
    "        encoding=encoding,\n",
    "        input_size=input_dim,\n",
    "        output_size=output_dim,\n",
    "        hidden_dim=P,\n",
    "        n_hid_layers=L,\n",
    "        device=device,\n",
    "        init_std=gain,\n",
    "        non_linearity=nonlinearity,\n",
    "    )\n",
    "    ## Setup compiler\n",
    "\n",
    "    # Define Loss, Optimizer\n",
    "    criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    compiler = Compiler(model, criterion, optimizer)\n",
    "    compiler.trackers = {\n",
    "        \"loss\": ScalarTracker(lambda: compiler.validation(tracked_datasets)),\n",
    "        \"hidden\": ActivationTracker(\n",
    "            model,\n",
    "            lambda inputs: model(inputs)[1][hidden_layer],\n",
    "            datasets=tracked_datasets,\n",
    "        ),\n",
    "        \"output\": ActivationTracker(\n",
    "            model, lambda inputs: model(inputs)[0], datasets=tracked_datasets\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    ## Training run\n",
    "    with io.capture_output() as captured_output:\n",
    "        compiler.training_run(\n",
    "            train_datasets,\n",
    "            tracked_datasets,\n",
    "            n_epochs=n_epochs,\n",
    "            batch_size=100,\n",
    "        )\n",
    "\n",
    "    data_hid = compiler.trackers[\"hidden\"].get_trace()\n",
    "    data_output = compiler.trackers[\"output\"].get_trace()\n",
    "    query = f\"Epoch % {mod} == 0\"\n",
    "    data_hid = data_hid.copy().query(query)\n",
    "    data_output = data_output.copy().query(query)\n",
    "    h_A = [\n",
    "        np.array(data.loc[epoch, 0, \"A\"])\n",
    "        for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "    h_B = [\n",
    "        np.array(data.loc[epoch, 0, \"B\"])\n",
    "        for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "    y_A = [\n",
    "        np.array(data.loc[epoch, 0, \"A\"])\n",
    "        for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "    y_B = [\n",
    "        np.array(data.loc[epoch, 0, \"B\"])\n",
    "        for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "    ]\n",
    "\n",
    "    epochs = np.arange(0, len(h_A))\n",
    "\n",
    "    y_true_A, y_true_B = outputs[0], outputs[1]\n",
    "    dy2 = np.sum((y_true_B - y_true_A) ** 2)\n",
    "    h2 = np.array([np.sum((h_A[epoch] - h_B[epoch]) ** 2) for epoch in epochs])\n",
    "    y2 = np.array([np.sum((y_A[epoch] - y_B[epoch]) ** 2) for epoch in epochs])\n",
    "    w = np.array(\n",
    "        [\n",
    "            y2[epoch] - np.dot(y_true_A - y_true_B, y_A[epoch] - y_B[epoch])\n",
    "            for epoch in epochs\n",
    "        ]\n",
    "    )\n",
    "    y0_mean = np.sum((0.5 * ((y_A[0] + y_B[0]) - (y_true_B + y_true_A))) ** 2)\n",
    "\n",
    "    h0, y0, w0, dy = h2[0], y2[0], w[0], dy2\n",
    "    epochs = epochs * mod\n",
    "\n",
    "    ## Fit effective learning rates\n",
    "    eta_h_opt, eta_y_opt, loss = simulate.optimize_eta(\n",
    "        h2, y2, w, dx2, dy2, guesses=np.logspace(-6, 2, 100)\n",
    "    )\n",
    "\n",
    "    losses.append(loss)\n",
    "    Ps.append(P)\n",
    "    Ls.append(L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e02af9847f8f14625728f2f7147d07d87bda9043f1b0a8cf0822fa7c64756065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
