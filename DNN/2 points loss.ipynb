{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from tqdm import trange, tqdm\n",
    "from IPython.utils import io\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numba import njit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "import wandb\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "from data import fun_data, grid_data\n",
    "from preprocessing import Direct, Encoding, OneHot\n",
    "from compilation import Compiler, Tracker, ScalarTracker, ActivationTracker\n",
    "from activations import get_activations\n",
    "from data_analysis.automata import to_automaton_history\n",
    "from data_analysis.visualization.animation import SliderAnimation\n",
    "from data_analysis.visualization.activations import (\n",
    "    ActivationsAnimation,\n",
    "    FunctionAnimation,\n",
    "    PointAnimation,\n",
    ")\n",
    "from data_analysis.visualization.automata import AutomatonAnimation\n",
    "from data_analysis.visualization.epochs import EpochAnimation\n",
    "import data_analysis.visualization.publication as publication\n",
    "import simulate\n",
    "import two_points\n",
    "\n",
    "import models as models\n",
    "from models import MLP, CNN, ResNet\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load settings\n",
    "settings = \"default\"\n",
    "\n",
    "(\n",
    "    model_type,\n",
    "    nonlinearity,\n",
    "    gain,\n",
    "    lr,\n",
    "    P,\n",
    "    L,\n",
    "    n_epochs,\n",
    "    hidden_layer,\n",
    "    dx2,\n",
    "    dy2,\n",
    "    in_dim,\n",
    "    out_dim,\n",
    ") = (\n",
    "    pd.read_csv(\"model_settings/2 points.txt\", sep=\" \", header=0)\n",
    "    .loc[settings]\n",
    "    .to_numpy()\n",
    ")\n",
    "model_type = getattr(models, model_type)\n",
    "if nonlinearity == \"discontinuous\":\n",
    "    nonlinearity = simulate.Discontinuous.apply\n",
    "elif nonlinearity == \"none\":\n",
    "    nonlinearity = None\n",
    "else:\n",
    "    nonlinearity = getattr(torch.nn.functional, nonlinearity)\n",
    "\n",
    "mod = 1\n",
    "# factor = 4\n",
    "# n_epochs = int(factor * n_epochs)\n",
    "# lr = lr / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate data\n",
    "\n",
    "input_dim, output_dim = 1, 1\n",
    "\n",
    "# data, encoding = two_points.data_set(dx2, dy2, input_dim, output_dim, device)\n",
    "\n",
    "inputs = np.array([[-1] * input_dim, [-1 + np.sqrt(dx2)] * input_dim]) / np.sqrt(\n",
    "    input_dim\n",
    ")\n",
    "outputs = np.array([[0.6] * output_dim, [0.6 + np.sqrt(dy2)] * output_dim]) / np.sqrt(\n",
    "    output_dim\n",
    ")\n",
    "names = [\"A\", \"B\"]\n",
    "data = TensorDataset(\n",
    "    torch.from_numpy(inputs.astype(np.float32)).to(device),\n",
    "    torch.from_numpy(outputs.astype(np.float32)).to(device),\n",
    ")\n",
    "\n",
    "encoding = Encoding(dict(zip(names, inputs)))\n",
    "\n",
    "train_datasets = [data]\n",
    "val_dataset = [data]\n",
    "\n",
    "tracked_datasets = val_dataset + train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units per layer: 1\n",
      "Loss: 1.9249316765035442\n"
     ]
    }
   ],
   "source": [
    "losses, Ps, Ls = [], [], []\n",
    "\n",
    "L = 5\n",
    "hidden_layer = 2\n",
    "n_epochs = 10000\n",
    "\n",
    "for P in range(1, 30, 1):\n",
    "    print(f\"Number of units per layer: {P}\")\n",
    "    gain = 4 / P ** (1 / 2)\n",
    "    learning_rate = lr * (np.sqrt(P) / 10)\n",
    "    \n",
    "\n",
    "    losses_this_P = []\n",
    "    for _ in range(30):\n",
    "        ## Instantiate model\n",
    "        model = model_type(\n",
    "            encoding=encoding,\n",
    "            input_size=input_dim,\n",
    "            output_size=output_dim,\n",
    "            hidden_dim=P,\n",
    "            n_hid_layers=L,\n",
    "            device=device,\n",
    "            init_std=gain,\n",
    "            non_linearity=nonlinearity,\n",
    "        )\n",
    "        \n",
    "        ## Setup compiler\n",
    "        criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        compiler = Compiler(model, criterion, optimizer)\n",
    "        compiler.trackers = {\n",
    "            \"loss\": ScalarTracker(lambda: compiler.validation(tracked_datasets)),\n",
    "            \"hidden\": ActivationTracker(\n",
    "                model,\n",
    "                lambda inputs: model(inputs)[1][hidden_layer],\n",
    "                datasets=tracked_datasets,\n",
    "            ),\n",
    "            \"output\": ActivationTracker(\n",
    "                model, lambda inputs: model(inputs)[0], datasets=tracked_datasets\n",
    "            ),\n",
    "        }\n",
    "    \n",
    "        # input_1 = train_datasets[0][0][0]\n",
    "        # input_2 = train_datasets[0][1][0]\n",
    "        # pred_1 = model(input_1)[0]\n",
    "        # pred_2 = model(input_2)[0]\n",
    "        # input_1, input_2, pred_1, pred_2 = [\n",
    "        #     a.detach().numpy() for a in (input_1, input_2, pred_1, pred_2)\n",
    "        # ]\n",
    "        # G = np.linalg.norm(pred_2 - pred_1) ** 2 / np.linalg.norm(input_2 - input_1) ** 2\n",
    "        # print(f\"Overall gain: {G:.3e}\")\n",
    "    \n",
    "        ## Training run\n",
    "        with io.capture_output() as captured_output:\n",
    "            compiler.training_run(\n",
    "                train_datasets,\n",
    "                tracked_datasets,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=100,   \n",
    "            )\n",
    "        train_loss = compiler.trackers[\"loss\"].get_entry(-1)[0][0]\n",
    "        if train_loss > 1e-2:\n",
    "            continue\n",
    "    \n",
    "        data_hid = compiler.trackers[\"hidden\"].get_trace()\n",
    "        data_output = compiler.trackers[\"output\"].get_trace()\n",
    "        query = f\"Epoch % {mod} == 0\"\n",
    "        data_hid = data_hid.copy().query(query)\n",
    "        data_output = data_output.copy().query(query)\n",
    "        h_A = [\n",
    "            np.array(data.loc[epoch, 0, \"A\"])\n",
    "            for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "        ]\n",
    "        h_B = [\n",
    "            np.array(data.loc[epoch, 0, \"B\"])\n",
    "            for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "        ]\n",
    "        y_A = [\n",
    "            np.array(data.loc[epoch, 0, \"A\"])\n",
    "            for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "        ]\n",
    "        y_B = [\n",
    "            np.array(data.loc[epoch, 0, \"B\"])\n",
    "            for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "        ]\n",
    "    \n",
    "        epochs = np.arange(0, len(h_A))\n",
    "    \n",
    "        y_true_A, y_true_B = outputs[0], outputs[1]\n",
    "        dy2 = np.sum((y_true_B - y_true_A) ** 2)\n",
    "        h2 = np.array([np.sum((h_A[epoch] - h_B[epoch]) ** 2) for epoch in epochs])\n",
    "        y2 = np.array([np.sum((y_A[epoch] - y_B[epoch]) ** 2) for epoch in epochs])\n",
    "        w = np.array(\n",
    "            [\n",
    "                y2[epoch] - np.dot(y_true_A - y_true_B, y_A[epoch] - y_B[epoch])\n",
    "                for epoch in epochs\n",
    "            ]\n",
    "        )\n",
    "        y0_mean = np.sum((0.5 * ((y_A[0] + y_B[0]) - (y_true_B + y_true_A))) ** 2)\n",
    "    \n",
    "        h0, y0, w0, dy = h2[0], y2[0], w[0], dy2\n",
    "        epochs = epochs * mod\n",
    "    \n",
    "        ## Fit effective learning rates\n",
    "        eta_h_opt, eta_y_opt, loss = simulate.optimize_eta(\n",
    "            h2, y2, w, dx2, dy2, guesses=np.logspace(-6, 2, 100)\n",
    "        )\n",
    "        losses_this_P.append(loss)\n",
    "    loss = np.mean(losses_this_P)\n",
    "\n",
    "    losses.append(loss)\n",
    "    Ps.append(P)\n",
    "    Ls.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (4,3))\n",
    "\n",
    "N_start = 1\n",
    "\n",
    "publication.set_color_mixed(1)\n",
    "plt.plot(Ps[N_start-1:], losses[N_start-1:])\n",
    "plt.xlabel(\"Number of hidden units per layer\")\n",
    "plt.ylabel(\"Fit loss\")\n",
    "plt.ylim(0)\n",
    "publication.plt_show(save_path=\"plots/2_points/architecture/loss_vs_units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN",
   "language": "python",
   "name": "rnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e02af9847f8f14625728f2f7147d07d87bda9043f1b0a8cf0822fa7c64756065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
