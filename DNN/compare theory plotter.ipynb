{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from tqdm import trange, tqdm\n",
    "from IPython.utils import io\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numba import njit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "source = \"../source\"\n",
    "sys.path.append(source)\n",
    "\n",
    "from data import fun_data, grid_data\n",
    "from preprocessing import Direct, Encoding, OneHot\n",
    "from compilation import Compiler, Tracker, ScalarTracker, ActivationTracker\n",
    "from activations import get_activations\n",
    "from data_analysis.visualization.animation import SliderAnimation\n",
    "from data_analysis.visualization.activations import (\n",
    "    ActivationsAnimation,\n",
    "    FunctionAnimation,\n",
    "    PointAnimation,\n",
    ")\n",
    "from data_analysis.visualization.automata import AutomatonAnimation\n",
    "from data_analysis.visualization.epochs import EpochAnimation\n",
    "from data_analysis.visualization.publication import pub_show\n",
    "import data_analysis.visualization.publication as publication\n",
    "import simulate\n",
    "import two_points\n",
    "\n",
    "import models as models\n",
    "from models import MLP, CNN, ResNet\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "traj_path = \"plots/2 points/comparisons/\"\n",
    "\n",
    "publication.set_color_mixed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = pd.read_csv(\"model_settings/2 points.txt\", sep=\" \", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(setting, save=True):\n",
    "    ## Load settings\n",
    "    (\n",
    "        model_type,\n",
    "        nonlinearity,\n",
    "        gain,\n",
    "        lr,\n",
    "        P,\n",
    "        L,\n",
    "        n_epochs,\n",
    "        hidden_layer,\n",
    "        dx2,\n",
    "        dy2,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "    ) = settings.loc[setting].to_numpy()\n",
    "    model_type = getattr(models, model_type)\n",
    "    if nonlinearity == \"discontinuous\":\n",
    "        nonlinearity = simulate.Discontinuous.apply\n",
    "    elif nonlinearity == \"none\":\n",
    "        nonlinearity = None\n",
    "    else:\n",
    "        nonlinearity = getattr(torch.nn.functional, nonlinearity)\n",
    "\n",
    "    threshold = 1e-4\n",
    "    n_epochs_plot = 20000\n",
    "\n",
    "    ## Load data\n",
    "    def load_data(data_name):\n",
    "        data_path = f\"{traj_path}{data_name}.pkl\"\n",
    "        if os.path.exists(data_path):\n",
    "            with open(data_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    etas_h_dic, etas_y_dic, G_hs_dic, G_ys_dic = [\n",
    "        load_data(name) for name in [\"etas_h\", \"etas_y\", \"G_hs\", \"G_ys\"]\n",
    "    ]\n",
    "\n",
    "    if setting in etas_h_dic.keys():\n",
    "        eta_h_opts = etas_h_dic[setting]\n",
    "        eta_y_opts = etas_y_dic[setting]\n",
    "        G_hs = G_hs_dic[setting]\n",
    "        G_ys = G_ys_dic[setting]\n",
    "        print(\"Fit parameters succesfully loaded from previous run.\")\n",
    "    else:\n",
    "        ## Fit effective learning rates\n",
    "        print(\"Could not find previous fit parameters, fitting...\")\n",
    "        eta_h_opts, eta_y_opts = [], []\n",
    "        G_hs, G_ys = [], []\n",
    "        for _ in range(10):\n",
    "            data, encoding = two_points.data_set(dx2, dy2, 1, 1, device)\n",
    "\n",
    "            model = model_type(\n",
    "                encoding=encoding,\n",
    "                input_size=1,\n",
    "                output_size=1,\n",
    "                hidden_dim=P,\n",
    "                n_hid_layers=L,\n",
    "                device=device,\n",
    "                init_std=gain,\n",
    "                non_linearity=nonlinearity,\n",
    "            )\n",
    "\n",
    "            # Compute G\n",
    "            input_1 = data[0][0]\n",
    "            input_2 = data[0][1]\n",
    "            hid_1 = model(input_1)[1][hidden_layer]\n",
    "            hid_2 = model(input_2)[1][hidden_layer]\n",
    "            pred_1 = model(input_1)[0]\n",
    "            pred_2 = model(input_2)[0]\n",
    "            input_1, input_2, hid_1, hid_2, pred_1, pred_2 = [\n",
    "                a.detach().numpy()\n",
    "                for a in (input_1, input_2, hid_1, hid_2, pred_1, pred_2)\n",
    "            ]\n",
    "            G_h = (\n",
    "                np.linalg.norm(hid_2 - hid_1) ** 2\n",
    "                / np.linalg.norm(input_2 - input_1) ** 2\n",
    "            )\n",
    "            G_y = (\n",
    "                np.linalg.norm(pred_2 - pred_1) ** 2\n",
    "                / np.linalg.norm(hid_2 - hid_1) ** 2\n",
    "            )\n",
    "            G_hs.append(G_h)\n",
    "            G_ys.append(G_y)\n",
    "\n",
    "            criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "            compiler = Compiler(model, criterion, optimizer)\n",
    "            compiler.trackers = {\n",
    "                \"loss\": ScalarTracker(lambda: compiler.validation([data])),\n",
    "                \"hidden\": ActivationTracker(\n",
    "                    model,\n",
    "                    lambda inputs: model(inputs)[1][hidden_layer],\n",
    "                    datasets=[data],\n",
    "                ),\n",
    "                \"output\": ActivationTracker(\n",
    "                    model, lambda inputs: model(inputs)[0], datasets=[data]\n",
    "                ),\n",
    "            }\n",
    "\n",
    "            h0, y0, w0 = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "\n",
    "            with io.capture_output() as captured:\n",
    "                compiler.training_run([data], [data], n_epochs=n_epochs, batch_size=100)\n",
    "\n",
    "            if compiler.trackers[\"loss\"].get_entry(-1)[0][0] > threshold:\n",
    "                continue\n",
    "\n",
    "            data_hid = compiler.trackers[\"hidden\"].get_trace().copy()\n",
    "            data_output = compiler.trackers[\"output\"].get_trace().copy()\n",
    "            h_A = [\n",
    "                np.array(data.loc[epoch, 0, \"A\"])\n",
    "                for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            h_B = [\n",
    "                np.array(data.loc[epoch, 0, \"B\"])\n",
    "                for epoch, data in data_hid.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            y_A = [\n",
    "                np.array(data.loc[epoch, 0, \"A\"])\n",
    "                for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            y_B = [\n",
    "                np.array(data.loc[epoch, 0, \"B\"])\n",
    "                for epoch, data in data_output.query(\"Dataset == 0\").groupby(\"Epoch\")\n",
    "            ]\n",
    "            epochs = np.arange(0, len(h_A))\n",
    "            y_true_A, y_true_B = data[0][1].numpy(), data[1][1].numpy()\n",
    "            dy2 = np.sum((y_true_B - y_true_A) ** 2)\n",
    "            h2 = np.array([np.sum((h_A[epoch] - h_B[epoch]) ** 2) for epoch in epochs])\n",
    "            y2 = np.array([np.sum((y_A[epoch] - y_B[epoch]) ** 2) for epoch in epochs])\n",
    "            w = np.array(\n",
    "                [\n",
    "                    y2[epoch] - np.dot(y_true_A - y_true_B, y_A[epoch] - y_B[epoch])\n",
    "                    for epoch in epochs\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            eta_h_opt, eta_y_opt = simulate.optimize_eta(h2, y2, w, dx2, dy2)\n",
    "            eta_h_opts.append(eta_h_opt)\n",
    "            eta_y_opts.append(eta_y_opt)\n",
    "\n",
    "        ## Save data\n",
    "        datas = [eta_h_opts, eta_y_opts, G_hs, G_ys]\n",
    "        data_dics = [etas_h_dic, etas_y_dic, G_hs_dic, G_ys_dic]\n",
    "        data_names = [\"etas_h\", \"etas_y\", \"G_hs\", \"G_ys\"]\n",
    "        for data, data_dic in zip(datas, data_dics):\n",
    "            data_dic[setting] = data\n",
    "\n",
    "        for data_dic, data_name in zip(data_dics, data_names):\n",
    "            data_path = f\"{traj_path}{data_name}.pkl\"\n",
    "            with open(data_path, \"wb\") as f:\n",
    "                pickle.dump(data_dic, f)\n",
    "\n",
    "    eta_h, eta_y = np.mean(eta_h_opts), np.mean(eta_y_opts)\n",
    "    G_h, G_y = np.mean(G_hs), np.mean(G_ys)\n",
    "\n",
    "    print(f\"eta_h, eta_y, G_h, G_y = {eta_h}, {eta_y}, {G_h}, {G_y}\")\n",
    "\n",
    "    dx2 = 1\n",
    "\n",
    "    h0s, y0s, w0s, hs, ys, ws = [], [], [], [], [], []\n",
    "    dy2s = []\n",
    "\n",
    "    N = 50\n",
    "    m = 1\n",
    "\n",
    "    print(\"Computing dy plot...\")\n",
    "    for dy in np.linspace(0, 1, N):\n",
    "        dy2 = dy**2\n",
    "        variables = []\n",
    "        for _ in range(m):\n",
    "            ## Generate data\n",
    "            data, encoding = two_points.data_set(dx2, dy2, 1, 1, device)\n",
    "\n",
    "            ## Instantiate model\n",
    "            model = model_type(\n",
    "                encoding=encoding,\n",
    "                input_size=1,\n",
    "                output_size=1,\n",
    "                hidden_dim=P,\n",
    "                n_hid_layers=L,\n",
    "                device=device,\n",
    "                init_std=gain,\n",
    "                non_linearity=nonlinearity,\n",
    "            )\n",
    "\n",
    "            criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr / 3)\n",
    "            compiler = Compiler(model, criterion, optimizer)\n",
    "            compiler.trackers = {\n",
    "                \"loss\": ScalarTracker(lambda: compiler.validation([data]))\n",
    "            }\n",
    "\n",
    "            h0, y0, w0 = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "\n",
    "            ## Training run\n",
    "            with io.capture_output() as captured:\n",
    "                compiler.training_run(\n",
    "                    [data],\n",
    "                    [],\n",
    "                    n_epochs=n_epochs_plot,\n",
    "                    batch_size=100,\n",
    "                    conv_thresh=threshold,\n",
    "                )\n",
    "\n",
    "            if compiler.trackers[\"loss\"].get_entry(-1)[0][0] > threshold:\n",
    "                break\n",
    "\n",
    "            h, y, w = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "\n",
    "            variables.append([h0, y0, w0, h, y, w])\n",
    "\n",
    "        if len(variables) > 0:\n",
    "            variables = np.mean(np.array(variables), axis=0)\n",
    "            for i, array in enumerate((h0s, y0s, w0s, hs, ys, ws)):\n",
    "                array.append(variables[i])\n",
    "            dy2s.append(dy2)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            fig = plt.figure(figsize=(3, 3))\n",
    "            plt.scatter(np.sqrt(dy2s), hs)\n",
    "            plt.xlabel(\"$||y_2-y_1||$\")\n",
    "            plt.ylabel(\"$||dh||^2$\")\n",
    "            plt.ylim(0, 1.1 * max(hs))\n",
    "            A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2s) * np.sqrt(dx2)\n",
    "            A_high = (G_h - G_y * eta_h / eta_y) * dx2\n",
    "            plt.plot(\n",
    "                np.sqrt(dy2s),\n",
    "                0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2),\n",
    "                linestyle=\"--\",\n",
    "                label=\"Theory\",\n",
    "            )\n",
    "            plt.legend()\n",
    "            pub_show(colors=\"contrast\")\n",
    "\n",
    "    def plot_y():\n",
    "        A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2s) * np.sqrt(dx2)\n",
    "        A_high = (G_h - G_y * eta_h / eta_y) * dx2\n",
    "        fig = plt.figure(figsize=(2.5, 2.5))\n",
    "        plt.scatter(np.sqrt(dy2s), hs)\n",
    "        plt.xlabel(\"$||y_2-y_1||$\")\n",
    "        plt.ylabel(\"$||dh||^2$\")\n",
    "        plt.ylim(0, 1.1 * max(hs))\n",
    "        plt.plot(\n",
    "            np.sqrt(dy2s),\n",
    "            0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2),\n",
    "            linestyle=\"--\",\n",
    "            label=\"Theory\",\n",
    "        )\n",
    "\n",
    "    plot_y()\n",
    "    pub_show(\n",
    "        colors=\"contrast\",\n",
    "        save_path=traj_path + \"dh_vs_y_\" + setting + \"_no_legend\" + \".png\",\n",
    "    )\n",
    "    plot_y()\n",
    "    plt.legend()\n",
    "    pub_show(\n",
    "        colors=\"contrast\",\n",
    "        save_path=traj_path + \"dh_vs_y_\" + setting + \".png\",\n",
    "    )\n",
    "\n",
    "    dy2 = 0.5\n",
    "\n",
    "    h0s, y0s, w0s, hs, ys, ws = [], [], [], [], [], []\n",
    "    dx2s = []\n",
    "\n",
    "    N = 50\n",
    "    m = 1\n",
    "\n",
    "    print(\"Computing dx plot...\")\n",
    "    for dx in np.linspace(0.2, 1, N):\n",
    "        dx2 = dx**2\n",
    "        variables = []\n",
    "        for _ in range(m):\n",
    "            ## Generate data\n",
    "            data, encoding = two_points.data_set(dx2, dy2, 1, 1, device)\n",
    "\n",
    "            ## Instantiate model\n",
    "            model = model_type(\n",
    "                encoding=encoding,\n",
    "                input_size=1,\n",
    "                output_size=1,\n",
    "                hidden_dim=P,\n",
    "                n_hid_layers=L,\n",
    "                device=device,\n",
    "                init_std=gain,\n",
    "                non_linearity=nonlinearity,\n",
    "            )\n",
    "\n",
    "            criterion = lambda x, y: 0.5 * nn.functional.mse_loss(x, y)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr / 3)\n",
    "            compiler = Compiler(model, criterion, optimizer)\n",
    "            compiler.trackers = {\n",
    "                \"loss\": ScalarTracker(lambda: compiler.validation([data]))\n",
    "            }\n",
    "\n",
    "            h0, y0, w0 = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "\n",
    "            ## Training run\n",
    "            with io.capture_output() as captured:\n",
    "                compiler.training_run(\n",
    "                    [data],\n",
    "                    [],\n",
    "                    n_epochs=n_epochs_plot,\n",
    "                    batch_size=100,\n",
    "                    conv_thresh=threshold,\n",
    "                )\n",
    "\n",
    "            if compiler.trackers[\"loss\"].get_entry(-1)[0][0] > threshold:\n",
    "                break\n",
    "\n",
    "            h, y, w = two_points.get_h_y_w(data, model, hidden_layer)\n",
    "\n",
    "            variables.append([h0, y0, w0, h, y, w])\n",
    "\n",
    "        if len(variables) > 0:\n",
    "            variables = np.mean(np.array(variables), axis=0)\n",
    "            for i, array in enumerate((h0s, y0s, w0s, hs, ys, ws)):\n",
    "                array.append(variables[i])\n",
    "            dx2s.append(dx2)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            fig = plt.figure(figsize=(2.5, 2.5))\n",
    "            plt.scatter(np.sqrt(dx2s), hs)\n",
    "            plt.xlabel(\"$||x_2-x_1||$\")\n",
    "            plt.ylabel(\"$||dh||^2$\")\n",
    "            plt.ylim(0, 1.1 * max(hs))\n",
    "            A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2) * np.sqrt(dx2s)\n",
    "            A_high = (G_h - G_y * eta_h / eta_y) * dx2\n",
    "            plt.plot(\n",
    "                np.sqrt(dx2s),\n",
    "                0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2),\n",
    "                linestyle=\"--\",\n",
    "                label=\"Theory\",\n",
    "            )\n",
    "            plt.legend()\n",
    "            pub_show()\n",
    "\n",
    "    def plot_x():\n",
    "        fig = plt.figure(figsize=(2.5, 2.5))\n",
    "        plt.scatter(np.sqrt(dx2s), hs)\n",
    "        plt.xlabel(\"$||x_2-x_1||$\")\n",
    "        plt.ylabel(\"$||dh||^2$\")\n",
    "        plt.ylim(0, 1.1 * max(hs))\n",
    "        A_low = np.sqrt(eta_h / eta_y) * np.sqrt(dy2) * np.sqrt(dx2s)\n",
    "        A_high = (G_h - G_y * eta_h / eta_y) * np.array(dx2s)\n",
    "        plt.plot(\n",
    "            np.sqrt(dx2s),\n",
    "            0.5 * A_high + np.sqrt(0.25 * A_high**2 + A_low**2),\n",
    "            linestyle=\"--\",\n",
    "            label=\"Theory\",\n",
    "        )\n",
    "\n",
    "    plot_x()\n",
    "    pub_show(\n",
    "        save_path=traj_path + \"dh_vs_x_\" + setting + \"_no_legend\" + \".png\",\n",
    "    )\n",
    "    plot_x()\n",
    "    plt.legend()\n",
    "    pub_show(save_path=traj_path + \"dh_vs_x_\" + setting + \".png\")\n",
    "\n",
    "    return eta_h_opts, eta_y_opts, G_hs, G_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas_h, etas_y, G_hs, G_ys = {}, {}, {}, {}\n",
    "for setting in settings.index:\n",
    "    print(f\"\\t\\t\\t\\t\\t-----{setting.upper()}-----\")\n",
    "    eta_h_opts, eta_y_opts, G_h, G_y = make_plots(setting, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
